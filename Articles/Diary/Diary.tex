\documentclass[12pt]{report}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{color}
\usepackage{txfonts}
\usepackage{float}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{pdfpages}
\usepackage{listings}
\usepackage{tikz}
\usetikzlibrary{arrows} 
\usepackage{enumitem}
\usepackage{rotating}

\begin{document}
\chapter{TODO}

\begin{itemize}
	\item Assemblage : Etat de l'art
	\item Correction : Continuer état de l'art + trier par idée
	\item Lire Hybrid SPAdes
\end{itemize}

\chapter{Année 1 : 2016 - 2017}

\section{Jour 1}

\begin{itemize}
  \item Relecture mémoire M2

  \item Relecture résultats

  \item Réappropriation sujet
\end{itemize}

\section{Jour 2}

\begin{itemize}
  \item Correction de bugs dans l'algo de correction

  \item Test de l'algo
\end{itemize}

\section{Jour 3}

\begin{itemize}
  \item Lecture article CoLoRMap

  \item Renommage des SR test par leur nom correct

  \item Tests et étude des overlaps
\end{itemize}

\section{Jour 4}

\begin{itemize}
  \item Etude des propriétés des autres outils de correction

  \item Appropriation des idées pour le notre

  \item Remplir les gaps avec les bases non corrigées du RL (idée + début)
\end{itemize}

\section{Jour 5}

\begin{itemize}
  \item Papiers administration

  \item Achat voiture
\end{itemize}

\section{Jour 8}

\begin{itemize}
  \item Possibilité de remplir les gaps avec bases non corrigés du RL si gap < maxgap

  \item RL ainsi produits : Bases corrigées en min, bases erronées en maj

  \item Début automatisation traitement en C + débarrassage fichiers seeds
\end{itemize}

\section{Jour 9}

\begin{itemize}
  \item Fin automatisation traitement en C

  \item Tests comparatifs outils automatisé / outil géré par bash

  \item => Automatisation plus lente que de passer par bash

  \item Test de la qualité des résultats f(maxgap)
\end{itemize}

\section{Jour 10}

\begin{itemize}
  \item Automatisation création du fichiers de seeds (en bash)

  \item Automatisation des tests (run algo, alignement résultats, calcul précision)

  \item Installation PgSA

  \item Dénombrement des templates bien couverts (maxgap = 0)
\end{itemize}

\section{Jour 11}

\begin{itemize}
  \item Séminaire (P. Caron)

  \item Papiers administratifs (création agent / financement machine)

  \item Dénombrement des templates bien couverts

  \item Premier test sur PgSA
\end{itemize}

\section{Jour 12}

\begin{itemize}
  \item Dénombrement des templates bien couverts

  \item Pblat : lmin rendu paramétrable

  \item Pblat : seuil pour match total (aligné sur >= xx\% de la longueur = match total) rendu paramétrable
\end{itemize}

\section{Jour 15}

\begin{itemize}
  \item Pblat : Pas de lmin inutiles dans les fonctions (visiblement)

  \item Algo : Plus de snprintf, remplacés par des fprintf

  \item Algo : get\_tpl\_seq corrigé -> Ne prend le tpl que si pas suivi d'un autre chiffre

  \item Algo : Premier clean-up de code + optimisation

  \item Algo : Tests en variant lmin / lmax

  \item Devis PC
\end{itemize}

\section{Jour 16}

\begin{itemize}
  \item Tests sur lmin / lmax / th et conclusions

  \item Comparatifs pblat basique / pblat modifié

  \item Début lecture survey

  \item Commentaires .h

  \item  Algo : Besoin d'un consensus entre les seeds

  \item Déménagement frigo (1h)
\end{itemize}

\section{Jour 17}

\begin{itemize}
  \item Récupération jeu de données bien nommé et complet

  \item Correction script stats, pour l'adapter au nouveau jeu de données + modification recherche longueur du template (virer le \_1 à la fin du nom du contig)

  \item Recalcul des alignements SR sur LR (fichiers psl)

  \item Recalcul des résultats (SR 1 \& 2 et params par défaut) + tableau

  \item 2ème étape de recrutement semble inutile (peu de pref / suff recrutés)

  \item => Vérification si préfixes / suffixes présents dans les gaps des tpl corrigés

  \item Survol du survey de correction, semble peu intéressant, bien que présente les différents types d'erreurs en fonction de la technologie de séquençage choisie, les fréquences / seuils / tailles pour les k-mers, subs vs subs + indels, modèles statistiques pour les erreurs, les répétitions / haplotypes, méthodes de corrections en fonction de plateforme utilisée => RIEN SUR NANOPORE A PART NANOCORR

  \item Installation de NaS et premiers tests

  \item Ebauche poster fête de la science
\end{itemize}

\section{Jour 18}

\begin{itemize}
  \item Recalcul des résultats (SR 1 \& 2 et params par défaut) + tableau

  \item Dénombrement des pref / suff recrutés lors de la deuxième étape (lmax = 10 / lmax =50)

  \item => Extrêmement peu de recrutement, aussi bien dans 1D que 2D
\end{itemize}

\section{Jour 19}

\begin{itemize}
  \item Recalcul des résultats (SR 1 \& 2 et params par défaut)

  \item Réunion w/ TL

  \item Installation et problèmes avec NaS

  \item Gros problèmes de Wi-Fi

  \item Signature contrat + Documents mission / remboursement / etc
\end{itemize}

\section{Jour 20}

\begin{itemize}
  \item Recalcul des résultats (SR 1 \& 2)

  \item Noms uniques pour fichier seeds et tmp.psl

  \item Possibilité de lancer plusieurs instances de l'algo en même temps

  \item Travail sur poster
\end{itemize}

\section{Jour 21}

\begin{itemize}
  \item Recalcul des résultats (SR 1 \& 2)

  \item MinION6 2D : EXTREMEMENT LONG

  \item Travail sur poster (Intro / schéma / comparatif séquenceurs) -> une moitié terminée
\end{itemize}

\section{Jour 22}

\begin{itemize}
  \item Poster terminé (8h -> 13h30)

  \item Tableau résultats SR1 \& SR2

  \item Tableau résultats filtrés (qualité de tous les contigs > 90\% pour pouvoir corriger un read)
  \item NaS => Problème = Newbler (runAssembly project)
\end{itemize}

\section{Jour 23}

\begin{itemize}
  \item Tableau résultats filtrés (un contig avec q > 90\% pour pouvoir corriger un read)

  \item Création de deux scripts de filtrage (all contigs >= 90 \& un contig >= 90) + génération auto ligne tableau résultats

  \item Tableau comparatif NaS / nous

  \item Tests sur NaS, toujours pas fonctionnel => path à modifier pour last / runassembly

  \item Résumé Colormap sur pdf

  \item Réunion w/ TL \& AL, pistes de travail (mates, utilisation de GkA, assemblage SR puis mapping LR)
\end{itemize}

\section{Jour 24}

\begin{itemize}
  \item Installation de Minia + premiers tests assemblage \& mapping RL sur SR assemblés + tableau résultats + stats rapides des LR matchant sur plusieurs contigs

  \item Début lecture papier Minia (reste 1 page)

  \item Installation de CoLoRMap + test perfs  => très long

  \item Recherche pblat paired end => Ne semble pas être possible

  \item Installation inchworm (pour pblat en paired end) => Bug avec psl2sam.pl

  \item Résultats algo sans 2nde étape (calculs)

  \item Erreur MinION : Détection par 6 nucléotides, donc séparation difficiles si homopolymères de longueur > 6 (suppressions favorisées, 66\% des erreurs observées)

  \item Commande pour laisser programmes tourner sur le serveur : nohup
\end{itemize}

\section{Jour 25}

\begin{itemize}
  \item Fin lecture Minia

  \item Séminaire Lyndon

  \item Fin temps exec algo (étape 1 seulement) avec SR1 \& SR2 => Fail car .fa résultat non supprimé lors de l'exécution => Relancement des tests en soirée

  \item Test Colormap sur jeu exemple du papier + sur ensemble de LR MinION => Beaucoup trop long sur MinION (+ de 3h)

  \item Algo : Suppression des fichiers temporaires une fois le traitement terminé

  \item Revue poster avec mme Selmi
\end{itemize}

\section{Jour 26}

\begin{itemize}
  \item Modifications poster

  \item Tableau résultats (Etape 1 seulement, SR1 \& SR2 concaténés)

  \item Récupération temps exec Colormap sur MinION : + de 16h => TROP LONG

  \item Recherche sur inchworm, pour maper avec BLAT en paired-end

  \item Calcul résultats avec Etape 1 ET Etape 2 (SR1 \& SR2 concaténés)
\end{itemize}

\section {Mois 2 : Octobre 2016}

\section{Jour 29}

\begin{itemize}
  \item Visite médicale

  \item Parallel : Possibilité de lancer l'algo sur x cores en même temps => Enorme gain de temps

  \item Paired-end reads : Impossible d'estimer la distance entre les deux sans mapping

  \item Nouveaux tests sur Minia => Non déterministe, ne produit jamais le même assemblage
\end{itemize}

\section{Jour 30}

\begin{itemize}
  \item Remise au propre du diary

  \item Recalcul des temps d'exécution avec parallel
	
	\item Tableau assemblage puis mapping LR sur PDF pour réunion
	
	\item Statistiques sur pairs de reads mappés sur même LR template
	
	\item Statistiques sur distance entre les deux reads d'une paire
	
	\item Réunion w/ TL \& AL
\end{itemize}

\section{Jour 31}

\begin{itemize}
	\item Tri des articles dans répertoires
	
	\item Lecture BLAST
	
	\item Comparaison alignement PBLAT / BLAT / BLAST sur SR assemblés => Production fichier BLAST avec tous les alignements
	
	\item Filtrage des alignements (lmin <= |al| <= lmax) => Production fichier temporaire avec les alignements significatifs
	
	\item Filtrage des alignements pour trouver les LR mappés sur différents contigs => Production fichier temporaire avec les contigs liable
	
	\item Dénombrement et calcul taille moyenne des contigs liables / non liables par les LR
\end{itemize}

\section{Jour 32}

\begin{itemize}
	\item Analyse du fichier de contigs liables, afin de déterminer les liens et gaps entre les contigs liés par un même LR (matin)

	\item Filtrage des gaps / overlaps trop longs entre contigs sur lesquels s'est mappé un même LR (début) => comptage des contigs liables
	obtenus (après midi)
	
	\item Tentative automatisation du filtrage des alignements, du calcul des LR alignés sur plusieurs contigs et du filtrage des gaps trop
	longs avec parallel => GROS FAIL, GROSSE PERTE DE TEMPS, GROSSE GALERE A RETROUVER LES BONS RESULTATS (fin après midi)
\end{itemize}

\section{Jour 33}

\begin{itemize}
	\item Filtrage des gaps / overlaps trop longs entre contigs sur lesquels s'est mappé un même LR => Production du fichier final permettant
	de générer le graphe
	
	\item Reprogrammation de filterAlignments en C (getMultimaps et filterGaps bash plus rapide car utilisation de grep dans le
	script) => filterAlignments maintenant instantané
	
	\item Automatisation de la création du fichier final permettant de générer le graphe
	(Temps total : 2 min avec les 6 jeux MinION (All SR) - 2 min avec les 6 jeux MinION (|250| SR))
	
	\item Correction de bugs dans le script générant le fichier final permettant de générer le graphe (car production de mauvais résultats
	en cas d'enchainement de contigs non liable / liable / non liable / liable)
	
	\item Analyse d'un graphe minimal, afin de voir comment implémenter => Graphé orienté, noeuds = contigs, edges = LR + |gap|
\end{itemize}

\section{Jour 36}

\begin{itemize}
	\item Programmation d'une structure de graphe, afin de construire le graphe d'assemblage
	
	\item Modification du format du fichier permettant de générer le graphe
	
	\item Parcours du fichier de graphe et génération du graphe
	
	\item Programmation d'une fonction de parcours du graphe explorant tous les successeurs possible de chaque noeud
	
	\item Etude des résultats obtenus
\end{itemize}

\section{Jour 37}

\begin{itemize}
	\item Re-génération du graphe avec des différents paramètres => Semble plus cohérent de fixer un gap max et un overlap max
	plutôt qu'un gap et une extension min

	\item Reprise de la fonction de parcours afin de réaliser la plus grande extension possible lors de l'exploration de chaque noeud
	
	\item Etude des résultats obtenus (longueur max d'un contig VS longueur de l'assemblage), et de leur pertinence
	
	\item Plus long contig produit par Minia jamais liable => Nécessité d'un seuil d'overlap / gap max relatif à la longueur du contig et du LR ?
	
	\item L'assemblage en cas d'overlap semble produire des contigs de mauvaise qualité
	
	\item Reprogrammation de filterGaps en C
\end{itemize}

\section{Jour 38}

\begin{itemize}
	\item Modification du filtrage des multimaps : Au lieu de chercher les LR mappés sur plusieurs contigs, on cherche juste les LR avec
	plusieurs hits 
	
	\item Reprogrammation du fitlrage des multimaps en C : Maintenant instantané 
	
	\item Filtrage des multimaps inutile : Le filtrage des gaps écarte déjà les LR avec un unique mapping, et vérifie, en cas de double
	mapping, que les deux contigs de référence sont bien différents
	
	\item => Génération du fichier du graphe maintenant uniquement en C (sauf pour le lancement / tris de fichier : bash) et instantanée
	
	\item Ajout des free dans tous les programmes en C (Multimaps / filterGaps / assembleContigs)
	
	\item Génération de graphes avec différents maxGap pour les deux sous ensembles de LR pour réunion
	
	\item Nécessité d'avoir la position de début du gap en plus de sa longueur dans les edges du graphe
\end{itemize}

\section{Jour 39}

\begin{itemize}
	\item Fête de la science
	
	\item Réunion w/ TL
\end{itemize}

\section{Jour 40}

\begin{itemize}
	\item Fête de la science
\end{itemize}

\section{Jour 43}

\begin{itemize}
	\item Correction mineure dans algo correction MinION
	
	\item Génération des scaffolds lors du parcours du graphe
	
	\item Dénombrement couples / scaffolds en fonction de |al| min alignement => Tableau
	
	\item Stats. sur les scaffolds produits (longueur, qualité, \% du génome couvert, ...) en fonction de |al| min, |al| max = 500, plusieurs
	passages par noeud
\end{itemize}

\section{Jour 44}

\begin{itemize}
	\item Stats. sur les scaffolds produits (longueur, qualité, \% du génome couvert, ...) en fonction de |al| min, |al| max = 500, plusieurs
	passages par noeud
	
	\item Modification de la génération des scaffolds afin de pouvoir autoriser un petit overlap
	
	\item Stats sur les scaffolds GAP + OVERLAP + plusieurs passages => Semble peu intéressant car perte rapide de qualité, influence variable
	sur avLen des scaffolds + Minia aurait trouvé les overlaps
	
	\item Stats sur les scaffolds produits en fonction de |al| min, |al| max = 500, en ne passant qu'une fois par chaque noeud du graphe 
	=> Semble plus prometteur, bons résultats
	
	\item Augmentation de |al| max -> Autant de "couples", mais plus de scaffolds, génome de référence mieux couvert => Plus intéressant
\end{itemize}

\section{Jour 45}

\begin{itemize}
	\item Stats sur les scaffolds GAP + OVERLAP + un passage => Semble peu intéressant car perte rapide de qualité, influence variable
	sur avLen des scaffolds + Minia aurait trouvé les overlaps

	\item Recherche du seuil |al| min et |al| max idéal pour obtenir des scaffolds de bonne qualité et bien couvrir le génome de référence
	
	\item Mise en évidence d'un problème dans le parcours : Parfois impossible de "rabouter" plusieurs scaffolds qui devraient normalement
	n'en former qu'un (+ dessin dans PDF réunion)
	
	\item Stats sur les scaffolds produits en fonction de |al| min, |al| max = 500, en ne passant qu'une fois par chaque noeud du graphe
	et en raboutant les contigs => Mieux que de pouvoir repasser infiniment par chaque noeud, mais moins bon que de n'y passer qu'une fois
	
	\item Statistiques et comparaisons des différentes méthodes de parcours du graphe (avec et sans raboutage), avec variation maxGap, 
	maxOverlap, ...
\end{itemize}

\section{Jour 46}

\begin{itemize}	
	\item Gestion de mode de production de scaffolds raboutés : Toutes les parties + le tout OU juste le tout
	
	\item Tout ce qui a été fait précédemment était faux, car les contigs sans successeur étaient reportés dans le fichier de résultat
	=> reprise de TOUS les tableaux
	
	\item Réunion w/ TL, quelques pistes, mais peu d'idées
\end{itemize}

\section{Jour 47}

\begin{itemize}
	\item Relecture des résultats de notre GA => Parcours sans marquer les noeuds et avec variations sur |al| peut potentiellement mieux couvrir => Tableau 
	=> bonne couverture mais mauvaise qualité
	
	\item Choisir d'aller vers le noeud le plus proche à chaque fois permet d'augmenter la qualité mais diminue la couverture
	
	\item Mise en évidence d'un problème avec le raboutage => Produit un scaffold trop court => Correction à l'aide d'un MWE 
	(on copiait le contig au lieu du scaffold)
	
	\item Nouveaux tests avec le raboutage corrigé => Permet de BEAUCOUP MIEUX couvrir mais perte de qualité
	
	\item L'exécution sur l'ensemble de reads Illumina de taille 250 semble produire des résultats similaires
		
	\item Lecture du papier de Karlsson, totalement inintéressant => Détails sur reads MinION et sur le fait qu'on peut scaffolder avec 
	+ paramètres utilisés pour blast => beaucoup trop long (10-12h)
	
	\item Nouveaux tests, overlaps intéressants => Améliore avLEn, avQual, et genCov => très proche de la couverture à 100\%
		  (idéal à 2100 -150 1, si on ne va QUE vers le noeud le plus long à chaque fois, sans poursuivre avec un autre si déjà visité)
		  
	\item Reprise de tous les tableaux, car lors de l'exploration d'un noeud, si le noeud permettant l'extension max est déjà visité, 
	on peut poursuivre maintenant poursuivre avec un autre noeud => Permet de mieux couvrir, qualité similaire
\end{itemize}

\section{Jour 48}

\begin{itemize}
	\item Fin du remplissage des tableaux

	\item Nouvelle idée de parcours : Tout parcourir même si déjà visité, mais ne pas sortir les scaffolds commençant à un noeud
	se trouvant en milieu de parcours => Longueur et couverture similaire, meilleure qualité, mais TRÈS LONG
\end{itemize}

\section{Jour 50}

\begin{itemize}
	\item Assemblage avec ABYSS => Moins de contigs, visiblement de meilleure qualité et longueur, mais beaucoup plus long
	
	\item Mise en évidence d'un bug dans assembleContigs, lors de la lecture du fichier du graphe le contig destination est copié avec le \\n final => 
	Correction
	
	\item Tests de GA avec les contigs générés par ABYSS => Permet de quasiment tout couvrir mais assez mauvaise qualité pour le peu de bases LR introduites
	
	\item Tests de GA avec les contigs Minia, en sortant les contigs non traversés => Augmente la qualité et couvre un peu plus
	
	\item Stats sur les distances moyennes entre deux contigs liés par notre algo en fonction de de |al| min
		  => contigs liés généralement trop loin l'un de l'autre pour obtenir une bonne qualité et couverture
\end{itemize}

\section{Jour 51}

\begin{itemize}
	\item Début lecture Canu
	
	\item GA avec filtration des LR (on ne garde que les LR, |LR| <= 10k) => Peu concluant
	
	\item Idem avec les reads 2D seulement => Peu concluant
	
	\item Tentative de réalignement avec BLAST des LR sur les scaffodls obtenus + ré-exécution de l'algo => Très mauvais résultats, autant
	en qualité qu'en couverture
	
	\item Tentative de polishing des résultats de la GA avec Pilon => Permet un gain de qualité et un gain de couverture 
	=> Intéressant de run plusieurs fois ?
\end{itemize}

\section{Jour 52}

\begin{itemize}
	\item Fin lecture Canu 
	
	\item Suppression des fichiers inutiles du serveur
\end{itemize}

\section{Jour 53}

\begin{itemize}
	\item Tentatives de polishing, mais bugs avec Pilon => Bizarre car marchait la veille
	
	\item Réécriture du fonctionnement de Canu sur PDF + éclaircissement de certains points
	
	\item Calcul des distances de mappings entre scaffold produit et contig le plus à gauche du scaffold => Généralement très éloignés l'un de l'autre
	
	\item Réunion w/ TL \& TL (27/10/16) => Nouvelle pistes de travail (Consensus sur les LR dans les gaps, nouveau jeu de données, ...)
\end{itemize}

\section{Jour 54}

\begin{itemize}
	\item Téléchargement nouveau jeu de données (Ecoli)
	
	\item Tri et extraction de données du grand ensemble de SR
	
	\item Assemblage des SR avec Minia + stats
	
	\item Dénombrement et étude des LR différents permettant de lier 2 contigs (avec variation |al| min max et gap min max, sur ADP) => Consensus possible
	=> On fait le consensus de toutes les portions de LR permettant de combler le gap entre 2 contigs en fixant la taille de chacune de ces portions
	à la taille du plus grand gap
	
	\item Test Canu sur ADP1 => 6h pour run
	
	\item EBI down : Impossible de télécharger les MinION de Ecoli
\end{itemize}

\section{Jour 57}

\begin{itemize}
	\item Étude des résultats de Canu sur ADP1 => Galère avec BWA

	\item Téléchargement des fichiers MinION de Ecoli (MAP005) + test de notre GA 
	=> Produit de très mauvais résultats => Les LR de MAP005 sont pourris, alignements à < 1\% d'identité sur génome de référence

	\item Test Canu sur MAP005 => Ne fonctionne pas => MAP005 trop pourri
	
	\item Début génération consensus des LR permettant de lier 2 contigs
\end{itemize}

\section{Jour 58}

\begin{itemize}
	\item Re-subsampling des SR Ecoli (pour Abyss)
	
	\item Assemblage des SR Ecoli avec Abyss et Minia + stats
	
	\item Génération consensus des LR permettant de lier 2 contigs
	
	\item Test GA avec consensus sur ADP1 => Bug
	
	\item Téléchargement MinION Ecoli (MAP006) => Meilleur que MAP005, alignements à 70\% identité
	
	\item Test Canu sur MAP006
\end{itemize}

\section{Jour 59}

\begin{itemize}
	\item Analyse résultats Canu (MAP006 et ADP1) => Excellents résultats
	
	\item Correction bug génération consensus => On dépassait parfois la fin de certains LR, d'où des résultats non déterminés
	
	\item Test GA sur ADP1 ; avec consensus (Minia et Abyss)
	
	\item Test GA sur MAP006 ; assemblage Minia ; sans consensus

	\item Test GA sur MAP006 ; assemblage Minia ; avec consensus
	
	\item Comparaison résultats avec / sans consensus => Consensus semble inutile car implique baisse de qualité et de couverture
	
	\item Nouvelle idée : Générer les "contigs" produits par méthode stage en corrigeant les LR, les blaster sur les contigs, et
		  réaliser la GA avec ces résultats plutôt avec les LR 
	
	\item Nouvelle idée : Corriger les LR avec Canu, blaster les LR corrigés sur les contigs, et réaliser la GA avec ces résultats plutôt
		  qu'avec les LR non traités
\end{itemize}

\section{Jour 60}

\begin{itemize}
	\item Tests et étude des résultats de la GA avec LR corrigés par Canu / parties "corrigées" par méthode du stage
	
	\item Bug dans la production de scaffolds : \\n parfois copié => Car reads corrigés par canu n'avaient pas un nom unique => corrigé

	\item Nouvelle idée : Générer les "contigs" produit par méthode stage en corrigeant les LR, et les assembler avec Minia / Abyss => Prometteur !
	
	\item => Mais PBLAT des SR sur les LR Ecoli extrêmement long
	
	\item Nouvelle idée : Tester l'alignement des séquences produites avec dnadiff => Intéressant seulement si très peu de contigs très longs
	
	\item Description des jeux de données (SR Ecoli, "contigs" produits par méthode stage, LR corrigés par Canu) sur PDF Réunions
	
	\item Réunion with AL \& TL (03/11/16) => Nouvelle idée prometteuse, mais nécessité de comparer les k-mers SR / LR
	
	\item Blast des SR sur les LR => Bcp trop long
	
	\item PBLAT de 1M SR sur LR Ecoli => 34 min, mais exécution de l'algo beaucoup trop lente
\end{itemize}

\section{Jour 61}

\begin{itemize}
	\item Installation et tests de Bowtie2
	
	\item Test de perfs des aligneurs (sur 1M et 12M reads Ecoli)	
	
	\item Ajout contigs SR et contigs régions correctes de LR dans un fichier puis assemblage => Peu intéressant
	
	\item Ajout contigs SR et régions correctes de LR dans un fichier puis assemblage => Peu intéressant
	
	\item Assemblage des régions correctes de LR avec Abyss => Possible avec ABYSS et non abyss-pe, mais produit de mauvais résultats qq soit taille kmer
	
	\item Comparaison Abyss / Abyss 2.0.2 en paired-ends => 2.0.2 plus efficace, produit moins de contigs, globalement plus longs
		  => Mais une fois contigs courts filtrés, résultats similaires, 2.0.2 couvre 0,2 \% du génome en plus
	
	\item Programmation script bash pour récupérer SR non mappés
	
	\item Ajout SR inutilisés et régions correctes de LR dans un fichier puis assemblage => Semble peu intéressant, quelle que
		  soit la combinaison utilisée, bien que test approximatif, car SR mal nommés lors du mapping (non prise en compte des /1 /2)
		  
	\item Etude format sortie Bowtie2 (SAM) pour voir comment récupérer les régions correctes des LR
	
	\item Lecture Jabba => Très intéressant
\end{itemize}

\section{Jour 63}

\begin{itemize}
	\item Tests récupération parties correctes LR Ecoli, avec algo Stage, 1M SR alignés avec PBLAT => Extrêmement long
	
	\item Tests perf Bowtie vs Bowtie2 vs SOAP2
	
	\item Génération parties correctes des LR à partir de fichier SAM => Régions des LR extraites de bonne qualité
	
	\item Test assemblage parties correctes LR Ecoli, avec algo Filtration, 1M SR alignés avec Bowtie2, very-fast => Mauvais résultats GA
	
	\item Test assemblage parties correctes LR Ecoli, avec algo Filtration, 12M SR p-e alignés avec Bowtie2, very-fast => Mauvais résultats GA
	
	\item Recalcul des alignements SR sur LR avec PBLAT, pour ADP1, avec SR renommés (prise en compte des /1 /2)
\end{itemize}

\section{Jour 64}

\begin{itemize}
	\item Retravail sur script récupérant les SR non mappés => Maintenant avec parallel, mais toujours long
		  
	\item Ajout des SR complets et régions correctes / contigs LR dans un même fichier puis assemblage => Pas concluant (pour ADP1)
	
	\item Test assemblage parties correctes LR Ecoli, avec algo Filtration, 12M SR s-e alignés avec Bowtie2, very-fast => Mauvais résultats GA
	
	\item Test assemblage parties correctes LR ADP1, avec algo Filtration, 12M SR s-e alignés avec Bowtie2, very fast => Mauvais résultats GA
	
	\item => Assembler les parties correctes des LR ne sert donc à rien
	
	\item Test de Guided Assembly sur Ecoli, avec Abyss => Aussi peu satisfaisant que Minia
		  
	\item Début de tentative d'ordre des contigs SR avec les LR.
		  => Construction d'un graphe pour "parcourir" les contigs liés
		  => Poids d'une "arrête" = nombre de LR permettant de lier c2 à droite de c1 
		  
	\item Lecture spaced k-mer machin => Peu intéressant, orienté résultats
	
	\item Nouvelle idée : Ajouter les reverse-complement de chaque contig => Plus mauvais résultats que sans RC pour la GA, 
		  mais semble intéressant pour l'ordre
	
	\item Nouvelle idée : Concaténer tous les LR et mapper les contigs SR sur le résultat obtenu => BWA mem ne passe pas
\end{itemize}

\section{Jour 65}

\begin{itemize}
	\item Programmation d'un graphe et d'algos de parcours permettant de générer l'ordre des contigs
	
	\item Filtrer les alignements en fonction de leur identité => Améliore les résultats de la GA, mais pas suffisamment 
	
	\item Ordonner les contigs avec les LR semble difficile, même en utilisant les RC des contigs
	
	\item Nouvelle idée : Ajouter les RC des LR également => Mauvais résultats pour la GA
	
	\item Ordre des contigs avec RC contigs et RC LR => Semble possible d'en tirer qq chose
\end{itemize}

\section{Jour 66}

\begin{itemize}	
	\item Ajout SR inutilisés et régions correctes / contigs LR / etc dans un même fichier puis assemblage, avec l'intégralité
		  des SR non mappés, pour ADP1 avec Algo correction => Pas concluant
	
	\item Lecture de SSPACE-Longread
		  
	\item Test de SSPACE-Longread => Permet effectivement de relier certains contigs
	
	\item Ordonner les contigs avec mapping des LR dessus est donc possible
	
	\item Nouvelle idée : Poids d'une arrête = Nombre de LR permettant de lier c2 à droite de c1 + qualité des alignements
		  => Parcours du graphe permettant de relier les contigs en se basant sur la qualité des alignements prometteur
	
	\item Nouvelle idée : Poids d'une arrête = Nombre de LR permettant de lier + qualité * longueur des alignements = nombre de bases correctes alignées
		  => Essayer de déterminer les liens avec le nombre moyen de bases correctement alignées par lien (qual * len / nbLR)
	
	\item Réunion w/ TL (10/11/16) => Continuer à essayer d'ordonner les contigs, voir comment comparer les k-mers (diagramme de Venn)
	
	\item Nouvelle idée : Filtrer les alignements pour ne conserver les liens entre deux contigs que s'ils sont préfixes / suffixes,
		  et avec un alMin de taille la longueur des k-mers => Toujours pas concluant pour la GA, même en réduisant gapMax, la distance 
		  réelle entre deux contigs joints reste trop grande, mais semble prometteur pour l'ordre
		  
	\item Combiner poids des arrêtes = (qual * len / nbLR) + liens pref / suff uniquement avec alMin = k => Semble prometteur, mais
		  toujours certains contigs mal ordonnés => nécessité de trouver pourquoi
\end{itemize}

\section{Jour 67}

\begin{itemize}
	\item Prendre en compte si les LR mappés sont RC ou non 
	
	\item Positions début / fin de mapping des LR => Apporte de l'info ? => Oui, end < beg signifie que le hit est en resverse complement
	
	\item Prendre en compte alEnd > alBeg pour les LR et ne prendre un compte que les alignements préfixes / suffixes
		  sur les contigs => Pas concluant pour la GA (meilleure qualité mais bien moins bonne couverture), permet de bien ordonner
		  les contigs, mais un contig n'est généralement lié qu'à un seul autre, qui est parfois trop loin => pas assez de liens pour conclure qqch
		  
	\item Régions qui se mappent plusieurs fois = régions répétées ? => Visiblement non
	
	\item Les overlaps ont tendance à introduire des erreurs dans les placements
\end{itemize}

\section{Jour 70}

\begin{itemize}
	\item Compareads => Compare les reads et non les kmers

	\item Problème : nb de bases correctes = faux, car on ne prend en compte les alignements que d'un seul côté du lien,
		  donc pas possibilité d'en tirer une info pertinente
	
	\item Conséquence : Poids des arrêtes = nombre de LR reliant c1 à c2 et c'est tout

	\item Compter l'intégralité des liens entre 2 contigs et ordonner en prenant en compte ce poids
		  (ie si c1 c1 c1 c3 liés par un LR, on aura un poids de 3 pour c1 -> c3)
	
	\item Nécessité : Trouver les reads qui se mappent à plusieurs endroits et les splitter
	
	\item Ajout des RC des LR et des contigs => Plus de mappings, mais que des doublons
	
	\item Vérifier que end > beg pour ne pas avoir du duplicata avec les RC des reads et/ou des contigs 
		  (car end > beg = Mapping sur RC) => Sans vérification, tous les alignements sont produits en double
	
	\item Compter le nombre de mapping sur contig / RC(contig) afin de déterminer lequel est correct, avec résultats BLAST
		  => En comptant le nombre de mapping à l'endroit / à l'envers de chaque contig dans le fichier blast : Pas concluant aussi bien pour ADP que Ecoli
		  => En comptant le nombre de contigs liés à gauche et à droite dans le graphe : Pas concluant aussi bien pour ADP que Ecoli
		  
	\item Réunion ED
	
	\item Meilleurs résultats avec un autre aligneur ? => Téléchargement de BLASR, comme dans SSPACE-Longread, car fait pour aligner des LR
	
	\item Ajouter les RC des LR et des contigs est inutile, car BLAST et BLASR mappent quer -> ref dans les deux sens
\end{itemize}

\section{Jour 71}

\begin{itemize}
	\item Test de scaffolding avec les résultats de BLASR => Aussi peu intéressant qu'avec BLAST
	
	\item Comparaison résultats SSPACE / nous afin de voir où ça bloque => Probablement filtration
	
	\item Récupération du filtre de filtration de SSPACE, et production des alignements conservés dans un fichier => Produit un graphe
		  permettant de lier correctement les contigs
		  
	\item Comme pour SSPACE => Poids d'une arrête de c1 vers c2 : Nombre de lr + longueurs et scores alignements c1 + longueurs et scores alignements c2
		  
	\item Étude des liens obtenus => Comment déterminer comment parcourir le graphe ? Comment choisir entre read / RC(read) ?
		  => Tout produire, et pour chaque contig, regarder si contig ou RC(contig) produit le meilleur scaffold (le plus long / meilleur score / etc)
	
	\item Test de SSPACE sur Ecoli : Peu concluant (356 contigs => 154 scaffolds) => 2eme passe : 113 scaffolds
	
	\item Scaffolder semble peu intéressant => nécessité de trouver les k-mers des LR non présents dans les contigs
	
	\item Jellyfish : Permet de compter / exporter les k-mers dans un fasta
	
	\item Combiner Jellyfish + GkA => Visiblement 10h30 pour trouver tous les k-mers des LR non présents dans les contigs => Besoin de + rapide
\end{itemize}

\section{Jour 72}

\begin{itemize}
	\item Mauvais résultats de SSPACE peuvent venir d'Abyss qui ne coupe par les reads / contigs au niveau des régions répétées

	\item Installation et test de CLCbio + SSPACE => Pas efficace
	
	\item Rerun SSPACE + Abyss avec les paramètres de Karlsson => Bien pour ADP1, bof pour Ecoli avec tous les jeux MinION
	
	\item Filtration des courts contigs Ecoli (< 1000) et rerun de SSPACE => Beaucoup mieux pour Ecoli
	
	\item Qualité / Couverture des scaffolds SSPACE très bonne => Vraiment nécessaire de remplacer les N par les bases des LR ?

	\item Installation et tests des GkA => Construction très longue + impossible de chercher un k-mer à partir de sa séquence
	
	\item Bug dans GkA : Quand on recherche un k-mer de taille > 63, il apparaît dans tous les reads, même ceux composés uniquement d'une même lettre répétée
\end{itemize}

\section{Jour 73}

\begin{itemize}
	\item SeqBio
\end{itemize}

\section{Jour 74}

\begin{itemize}
	\item SeqBio
\end{itemize}

\section{Jour 77}
\begin{itemize}
	\item Test PgSA : Beaucoup trop long à construire

	\item Alignement des scaffolds produits par SSPACE avec BWA : Très mauvaise qualité => Probablement dû aux N ajoutés dans les gaps entre les contigs
	
	\item Semble y avoir peu de différence dans les résultats lors de l'utilisation de plusieurs jeux ou d'un seul jeu de MinION,
		  plus de MinION permet juste de couvrir plus (pour SSPACE)
		  
	\item Amélioration du code du Scaffolding
		  
	\item Remplissage des gaps par les bases des LR sur un exemple (ADP1) => Aussi bon que SSPACE avec dnadiff, BIEN MEILLEUR avec BWA
	
	\item Test parcours du graphe sur Ecoli => Ne fonctionne pas
	
	\item Le scaffold produit par SSPACE ne commence pas par le contig mappé en position 1, mais scaffolds marqués comme "circulaires" quand c'est le cas
		  
	\item Déterminer quel est le prochain contig : Avec le plus petit gap ? => Non
	
	\item SSPACE n'ordonne pas toujours bien les contigs, nécessité de mieux filtrer / mieux parcourir => Étudier l'ordre des contigs
		  et les liens de BLASR
\end{itemize}

\section{Jour 78}

\begin{itemize}
	\item Installation et tests sur les CGkA
	
	\item Correction parcours du graphe => Fonctionne avec Ecoli

	\item Travail sur le parcours du graphe avec exemple graphe Ecoli afin de déterminer un parcours meilleur que SSPACE
	
	\item Bug lors de la construction du graphe : Certaines arrêtes ne sont pas ajoutées => Problème vient du tableau de LR, qui
		  peut se collisionner avec les tableaux d'autres contigs => À corriger
		  
	\item Nécessité de trouver le contig le plus à gauche sur le Gen. Ref. non encore exploré pour faire le parcours ?
		  => Semble impossible si scaffold circulaire
	
	\item alMin = 3000 semble permettre de bien lier chaque contig à son successeur direct => Recalcul des résultats SSPACE + nous
		  => On semble être bien meilleur en utilisant BWA, pour ADP1
	
	\item Question : Pourquoi 284 scaffolds lorsqu'on ne filtre pas les < 1000 des 366 contigs Ecoli => Car SSPACE sort sous forme
		  de scaffold les contigs non utilisés lors du scaffolding
	
	\item Problème : Même avec notre technique, on ne mappe pas en position 1 sur le génome de référence
		  => Corrigé au jour 80 ; on ne choisissait pas la séquence RC du contig si le scaffold démarrait par un contig RC
\end{itemize}

\section{Jour 79}

\begin{itemize}
	\item Question : Comment comparer deux génomes ? => dnadiff semble splitter le génome query en plusieurs parties
		  => Si on split en moins de partie que SSPACE on est bon !
		  
	\item Comparaison résultats dnadiff entre nous et SSPACE en fonction de cov / qual et nombre de parties alignées (moins il y en a mieux c'est)
		  => On couvre mieux, un peu moins bonne qualité, et moins de parties alignées
	
	\item Comparaison résultats BWA entre nous et SSPACE en fonction de cov / qual
		  => On a une bien meilleure qualité
		  
	\item Recherche sur comment obtenir consensus de plusieurs séquence => Avec clustalw2 ? => Visiblement non car sort des caractères non-ACGT
	
	\item Correction bug génération scaffold avec Ecoli : Car le Ecoli-rccontigs.fa avait les contigs sur plusieurs lignes
	
	\item Bug du tableau des LR corrigé : Le problème venait de l'initialisation du tableau conseq servant à faire les consensus, avec i au lieu de size
		  comme indice
		  
	\item Débugage : Bug lors de la sortie des séquence des scaffolds, utilisation de valgrind => On copiait le \\0 trop loin
	
	\item Travail sur les CGkA pour pouvoir chercher par séquence et non par position => Calcul nombre de k-mers des LR
		  présents dans les contigs SR => Très peu
		  
	\item alMin = 3000 lie bien chaque contig à son successeur direct, mais produit plusieurs scaffolds, nécessaire de les relier entre eux
		  en raboutant, et d'obtenir un scaffold unique
\end{itemize}

\section{Jour 80}

\begin{itemize}
	\item Calcul du nombre de k-mers des LR présents dans le génome de référence => Très peu
	
	\item Calcul du nombre de k-mers des LR présents dans les SR => Très peu
	
	\item Recalcul des résultats et retests : Si on part du même contig de début que SSPACE, on obtient un scaffold de meilleure qualité
	
	\item Tests SSPACE / GA sur ADP1 avec 1DR => Mauvais résultats
	
	\item Lecture LSCPLus (Correction LR avec alignement SR) => Intéressant en utilisant nos extensions pref / suff ?
	
	\item Recherche dans code SSPACE : Comment choisit-il le premier contig ? => Il prend le plus long, fait les scaffolds,
		  et une fois les scaffolds produits, tente de les relier (là, il peut potentiellement prendre le RC d'un scaffold
		  si cela peut permettre la création d'un lien)
		  
	\item Modification du script de conversion de LSCPlus => Ne marchait pas bien
		  
	\item Test de LSCPlus sur ADP1, M12D => Mauvais résultats
\end{itemize}

\section{Jour 81}

\begin{itemize}
	\item Test de LSCPlus sur tout ADP1 => PAS ASSEZ D'ESPACE DISQUE
	
	\item Etude des MAW dans ref / LR / SR => Calculs longs
	
	\item Etude estimation des gaps / overlaps VS réalité sur ADP1 => Pas toujours juste, d'où l'impossibilité de mapper en un coup avec BWA
	
	\item Test avec consensus lors de gaps avec notre méthode => Diminue la qualité si on compte les occ des lettres
		  => Besoin de trouver une stratégie de consensus plus efficace
		  
	\item Étude des lens / scores nous vs SSPACE => Impossible de déterminer pourquoi ils sont différents, car les mêmes valeurs sont
		  ajoutées aux liens => Besoin de refaire une recherche afin de pouvoir avoir les mêmes résultats que 
		  SSPACE en prenant alMin = 1500 TODO
		  
	\item Correction de bugs dans le code de la GA (on ne remplissait pas le tableau de nom des contigs aux indices RC)
		  
	\item Comparaison nous / SSPACE sur un autre génome (Yeast) => Résultats semblent similaires à SSPACE (à raboutage prêt)
	
	\item Tests sur SSPACE en autorisant les hits à ne pas être uniquement préfixe / suffixe => Aucun changement
	
	\item Yeast est en fait composé de 30 séquences de "référence" différentes => On devrait obtenir 30 scaffolds, mais SSPACE
		  ne produit pas de bons résultats
		  
	\item Tests de notre méthode sans le filtre SSPACE, uniquement en définissant alMin, idMin, gapMin => Résultats semblant être
		  plus "continus" qu'avec le filtre sur Ecoli alMin = 1500, égaux au résultats avec filtre avec alMin = 3000
		  => MAIS le filtre sert à garder le meilleur alignement et non le premier de la liste en cas d'overlap trop important, et est donc utile
\end{itemize}

\section{Jour 82}

\begin{itemize}
	\item Implémentation du raboutage des scaffolds
	
	\item Corrections sur le code (rev-comp d'une séquence, ...)
	
	\item Tests finaux : On est meilleurs quoiqu'il arrive (sur Ecoli / ADP1)
	
	\item Téléchargement d'un nouveau génome (Arabidopsis)
	
	\item Test de LSCPlus sur plusieurs jeux de données : Mauvais résultats
\end{itemize}

\section{Jour 83}

\begin{itemize}
	\item Implémentation du "filtre" de SSPACE pour notre GA (différent de celui de SSPACE mais semble correct)
	
	\item Test assemblage des 64-mers LR non présents dans les contigs SR => Pas concluant
	
	\item Test avec notre méthode + répétitions => Pas concluant
	
	\item Réunion w/ TL => Besoin de chercher des k-mers espacés
	
	\item Test de comparaison des k-mers LR / SR / Ref / ... avec k = 32 => Toujours peu concluant
\end{itemize}

\section{Jour 84}

\begin{itemize}
	\item Assemblage des SR Arabidopsis avec Abyss (très long...)
	
	\item Recherche sur l'extraction de spaced k-mers
	
	\item Test alignement LR -> contigs avec BWASW => Comparable à BLASR en termes de temps, trop difficile de parser le .sam
	
	\item Comparaison assemblage NaS vs Gen. Ref. avec dnadiff => NaS est toujours bien meilleur
	
	\item Recherche des 16-mers, 8-mers des LR dans les contigs LR => 16+-mers espacés (avec un 8-mer de chaque côté) semble la meilleure option
	
	\item Test de Miniasm => Moins bon que SSPACE / Nous
	
	\item Mapping avec minimap => Presque instantané 
	
	\item Recherche sur les résultats de Minimap, pour voir si on peut scaffolder => Visiblement non
\end{itemize}

\section{Jour 85}

\begin{itemize}	
	\item Tests sur Minimap avec différents paramètres => Pas concluant

	\item Test assemblage des k-mers LR non présents dans les contigs SR => Pas concluant
	
	\item Séminaire
	
	\item abyss-pe long sur arabidopsis car needed subsampling => subsampled à 12M SR mais toujours très long + plante quand on lance d'autre processus
	
	\item Nouvelle idée : Assembler les k-mers des LR non présents dans les SR, et mapper les contigs obtenus assez longs sur les contigs SR
		  => Pas concluant actuellement car trop de k-mers uniquement LR,
		  mais peut être intéressant si on arrive à trouver un faible nombre de k-mers non présents ?
	
	\item Recalcul des k-mers LR présents dans les contigs des SR car erreur lors d'un test => Toujours mauvais résultats
	
	\item Recherche d'un nouveau génome sur lequel tester
	
	\item Test de DALIGNER => Instantané, mais comment voir les résultats ?
\end{itemize}

\section{Jour 86}

\begin{itemize}
	\item Réunion w/ TL \& AL => Pistes de travail pour l'indexation de spaced k-mers
	
	\item Assemblage des SR Arabidopsis avec Minia, car impossible avec Abyss => Ne produit aucun contig correct
	
	\item Problème !!! => Les SR arabidopsis sont en fait trop courts !
	
	\item Génération de SR arabidopsis avec ART, puis test nous vs SSPACE avec assemblage Minia (car SSPACE trop long)
		  SSPACE => Mauvais résultats avec al = 3 000 / overlap = 5 000 => car LR = PacBio 
		  SSPACE => Retest avec al = 1 500 / overlap = 9 000 => Mieux, mais toujours pas d'unique scaffold
		  Nous => On fait pire que SSPACE => BESOIN DE REVOIR COMMENT CHOISIR ENTRE F ET RC POUR DEBUTER UN SCAFF
		  => Mauvais résultats à cause de la taille des contigs Minia ?
	
	\item Installation et tests de Graphmap => Ne peut trouver qu'un mapping par LR => Inintéressant
	
	\item Recalcul recherche des k-mers LR avec RC => 2 x plus fois 64, 1,75 x plus avec 32, 2x plus avec 16, presque tout avec 8
	
	\item Étude des résultats de DALIGNER => Pas concluant, ne permet pas de relier convenablement
	
	\item Recherche des k-mers NaS dans contigs SR => Quasiment tous présents
	
	\item Nouvelle idée : Prendre un LR, rechercher tous ses k-mers (non chevauchant) de taille 128 dans l'ensemble
		  des MAW de taille 128 des SR => Aucun résultat
		  => Au final, revient à chercher les k-mers des LRs dans les k-mers des SR => Donc reprend notre idée de spaced k-mers
		  
	\item Assemblage avec Abyss (il ne faut aucun autre process en même temps)
	
	\item SSPACE vs Nous : On fait n'importe quoi
\end{itemize}

\section{Jour 89}

\begin{itemize}
	\item Étude de notre scaffolding, car résultats très différents de SSPACE sur Arabidopsis
	
	\item SSPACE produit également de mauvais chemins, dû au mauvais jeu de données SR, car trop faible couverture ?
		  => En effet, Karlsson recommande un coverage x1000, et le papier SSPACE également, alors qu'on était à 49
	
	\item Relecture papier GkA
	
	\item Tests sur MWE pour les spaced-GkA => Semble marcher
\end{itemize}

\section{Jour 90}

\begin{itemize}
	\item Regénération de SR avec ART (100x coverage) + assemblage Abyss
	
	\item Test SSPACE et Nous sur le nouveau jeu de données
	
	\item => Impossible, assemblage Abyss interminable
\end{itemize}

\section{Jour 91}

\begin{itemize}
	\item Re-MWE sur spaced-GkA 
	
	\item Étude sur comment faire un spaced SA => Simplement par tri des suffixes
	
	\item Test de LAST : Rapide, mais produit de mauvais liens + ne prend pas en compte les strands query / db
	
	\item Etude du code de GkA => Impossible de trouver comment remplacer le SA par un spaced-SA
	
	\item Reprise du code des tests de CGkA afin de rechercher des k-mers espacés
	
	\item Test de la recherche des k-mers espacés sur 8 -> 64, gap = 1
\end{itemize}

\section{Jour 92}

\begin{itemize}
	\item Test de la recherche de k-mers espacés, gap = 2, 3
	
	\item Test de la recherche de k-mers espacés, gap variable (jusque 10)
	
	\item Test de correction de LR à l'aide de seeds + unitigs overlapant => Pas concluant avec Minia (unitigs trop courts) 
		  ni avec Abyss (trop peu d'unitigs)
	
	\item Étude du code de CGkA pour remplacer SA par spaced-SA => Impossible de trouver également
	
	\item Bug sur la recherche de k-mers espacés ? Pas les mêmes résultats avec k-mers contigus et 0-spaced-k/2-mers ...
	
	\item Bug corrigé => Recalcul de recherche des k-mers espacés
	
	\item Nouvelle idée : Mapper les SR sur les LR, s'en servir comme seed, et relier les seeds à l'aide des GkA
\end{itemize}

\section{Jour 93}

\begin{itemize}
	\item Encore des bugs dans la recherche de k-mers espacés... => Correction
	
	\item Recalcul recherche k-mers espacés LR dans CSR => Pas concluant
	
	\item Construction CGkA des LR
	
	\item Test recherche des k-mers CSR dans LR => Pas concluant

	\item Test de reliage de seeds à l'aide des GkA => Bug, à reprendre
	
	\item Nouvelle idée : Recherche de spaced-k-mers de LR DANS les LR, afin de déterminer bons / mauvais k-mers
	
	\item Recherche des k-mers espacés LR dans CSR => Pas concluant
\end{itemize}

\section{Jour 96}

\begin{itemize}
	\item PBJelly2 : Même idée, mapper LR sur CSR avec BLASR, mais impossible à installer / tester
	
	\item Travail sur le reliage de seeds à l'aide des CGkA / PgSA => Impossible avec des reads de longueur différente => Problématique
	
	\item Subsampling de l'ensemble de SR ADP1 en ne gardant que ceux de longueur 301
	
	\item Retest de reliage de seeds avec CGkA => Très rarement des overlaps parfaits à k fixé
		  => Nécessaire de diminuer peu à peu la taille du k-mer recherché afin de trouver des overlaps
		  => Donc nécessaire d'utiliser PgSA
	
	\item Construction de l'index PgSA, et étude des fonctions traitant les requêtes 
\end{itemize}

\section{Jour 97}

\begin{itemize}
	\item Réunion w/ TL \& AL : Validation du spaced-GkA, idées pour la recherches de nouveaux spaced-k-mers, trimming des LR, ...
	
	\item Travail sur PgSA pour permettre de relier les seeds (tout l'aprem)
	
	\item Calcul des ensembles de k-mers des LR trimmés de 8
	
	\item Recherche des 64-0-10-spaced-k-mers, puis des 32 des non trouvés, etc => Bug car les k-mers non trouvés sont
		  écrits dans le fichier en RC => Correction et rerun
\end{itemize}

\section{Jour 98}

\begin{itemize}
	\item Recherche des 0-10-spaced-k-mers dans les 8-trimmed-LR => Pas concluant, donc erreurs pas en début-fin
		  mais aléatoires
	
	\item Bug dans la production des 32-mers => Recalculer les k-mers présents dans les CSR (peu de changement donc osef)
	
	\item Poursuite du travail sur PgSA => Mauvais résultats car certains SR sont de mauvaise qualité
		  => Correction des SR (avec Karect) et retest
		  => Karect trop long, test avec Lighter => N'améliore pas beaucoup la qualité, seulement +0,2 \% id
		 
	\item Pour le reliage avec PgSA => Si on utilise des spaced-SA, on pourra potentiellement mieux relier
		  (car tolérera qq erreurs de subs, parfait pour Illumina)
		  => NON EN FAIT, car un spaced-SA sert à rechercher des k-mers avec des gaps entre les bases 
		  et non des k-mers avec des mismatches
		  
	\item Recherche sur les spaced-SA => Un algo (DisLex) mais pas dispo, ou radix sort
\end{itemize}

\section{Jour 99}

\begin{itemize}
	\item Test de reliage avec PgSA en utilisant les SR corrigés par Lighter => Ne change rien
		  => Parfois dans jeu Illumina, présence de reads de faible qualité, qui font merder le reliage
		  
	\item Test de perM pour comparer les k-mers : Trouve un peu plus de k-mers que précédemment, mais pas top
		  non plus, prend en compte des erreurs de mismatches, et non des erreurs d'indels
		  => Bons résultats avec des 16-mers, car tolère une erreur par 8-mer, et car presque tous les 8-mers sont trouvés sans erreur
	
	\item Test reliage de deux reads très éloignés avec PgSA => Pas très efficace, car toujours certains SR 
		  de mauvaise qualité
	
	\item Nouvelle idée : Pour le reliage avec PgSA, le faire avec l'ensemble de k-mers des SR ? Permettra par ex. de trouver un lien
		  entre un SR et le milieu d'un autre SR
		  => Fonctionne en effet bcp mieux niveau qualité (même descendant à overlap = 10)
		  => Mais produit des liens plus courts, quoique agrandissable en baissant overlapMin
		  
	\item Prog d'un algo donnant le SA pour un pattern nb match - nb gap donné
	
	\item Différenciation spaced-seeds de la littérature, et spaced-k-mers définis par nous
\end{itemize}

\section{Jour 100}

\begin{itemize}
	\item Réunion w/ TL \& AL  => Rechercher des k-mers avec 20-21 bases solides, obtenir DisLex pour rechercher nos gapped-k-mers, continuer PgSA
	
	\item Recherche de k-mers avec 20-21 bases solides avec perM => Assez mauvais résultats, plus proche des 32-mers que des 16-mers
	
	\item Mail pour code source DisLex
	
	\item Test recherche de mot dans SSA et dans SA => Les SSA tels qu'on les a défini permettent bien de rechercher
		  des motifs avec gaps, et non avec mismatches => GOOD
	
	\item Travail sur reliage avec PgSA (utilisation des RC des k-mers) => Segmentation fault : A cause de k-mers en double ?
\end{itemize}

\section{Vavances de noël : Jours 101 - 117}

\begin{itemize}
	\item Retest génération PgSA avec RC 64-mers, en ne gardant qu'un exemplaire de chaque 64-mer => Bug toujours
	
	\item Génération PgSA avec RC 64-mers, en ne gardant que les 64-mers apparaissant au moins 2 fois => Works!
		  => Les "contigs" ainsi obtenus sont de bonne qualité, mais toujours difficile de relier 2 64-mers sans backtrack
	
	\item Recherche des 20-mers avec CgKA
	
	\item Recherche des 21-mers impossible : Car on ne peut charger en mémoire qu'un seul index, et diviser les k-mers à rechercher par deux
		  => Donc recherche des 22-mers à la place
		  
	\item Programmation du backtracking pour relier les seeds
		  => Ne marche pas bien sur l'exemple visant à relier 2 seeds mappés sur un LR
		  => Marche très bien, insta, 99\% id pour relier 2 seeds provenant du gen. ref.
\end{itemize}

\section{Jour 118}

\begin{itemize}
	\item Test de reliage de 2 seeds provenant du gen. ref. avec les SR 250bp de NaS => Identité de 100\%
	
	\item Relier des seeds provenant du mapping SR sur LR marche en fait
	
	\item Retravail sur la fonction de reliage, afin de ne pas return 10000 fois
	
	\item Travail sur pblat, afin de produire un fichier contenant les seeds à relier => Fait, en reprenant le code de l'algo du stage
	
	\item Problème : Encore des seeds de mauvaise qualité, du à la fusion => Nécessité de consensus ? De prendre seulement le meilleur ?
	
	\item Solution retenue : Quand il y a des chevauchements, on ne garde que le seed avec le plus de matches	
		  => Permet de n'avoir quasiment que des seeds s'alignant à 100\%, le plus faible = 99 \%
\end{itemize}

\section{Jour 119}

\begin{itemize}
	\item Problème : Certains k-mers des seeds ne sont pas présents dans le PgSA (sûrement parce qu'on a demandé au moins 2 occ de chaque k-mer avant
		  la construction) => Tests avec le sous-ensemble de reads de longueur 301
		  
	\item Même en retenant les seeds se mappant avec une bonne identité, toujours impossible de relier certains k-mers, semble-t-il
		  à cause d'erreurs de mismatches (généralement on tombe sur le k-mer cible à UN SEUL mismatch près)
		  
	\item Tentative de solution : Considérer les seeds comme liés quand on arrive sur un k-mer chevauchant le seed destination sur 2/3 de sa longueur
		  => Semble bête par rapport à la solution du dessous
		  
	\item Tentative de solution : Considérer les seeds comme liés quand on arrive sur un k-mer avec < n différences avec la cible
		  => Beaucoup plus correct
		  
	\item Idée : Utilisation d'un double PgSA (64 et 32 mers par ex) s'il est impossible de relier 2 seeds avec un k PgSA de taille k,
		  on en prend un plus petit ? => Non, car les k des PgSA est variable
	
	\item Problème : Backtracking bug encore mais c seulement la prog
\end{itemize}

\section{Jour 120}

\begin{itemize}
	\item Travail sur l'algo de reliage de seeds avec PgSA, correction de bugs, mise en évidence de problèmes
	
	\item Le backtracking fonctionne et retourne correctement
	
	\item La correction semble marcher au moins avec le jeu NaS
	
	\item Mise en évidence d'un problème si les seeds sont plus distants sur le gen. ref. que sur le LR
		  => Perte de qualité et augmentation temps d'exécution
	
	\item Toujours des problèmes avec les free
	
	\item Besoin de plus de seeds, car certaines zones du LR sont peu couvertes, et donc perte de longueur sur le LR corrigé
\end{itemize}

\section{Jour 121}

\begin{itemize}
	\item Travail sur algo reliage, notamment sur les free
	
	\item Idée : Utiliser des k-mers comme seeds
		  => Impossible, car pas assez de longueur pour être précis, on peut donc avoir des placements ne concordant pas sur le LR et sur le gen ref
		  (par ex, S2 à droite de S1 dans le LR, mais à gauche dans le gen. ref.), amenant à des impossibilité de reliure
		  
	\item On peut en fait avoir le même problème avec des SR complets comme seeds, mais c sûrement plus rare
	
	\item Recherche de paramètres pblat
	
	\item Erreurs de malloc / free semblaient venir de algo.c, qui produisait mal les séquences à relier
	
	\item Programmation d'une fusion des seeds s'ils se chevauchent correctement au lieu de juste garder celui avec la meilleure qualité
	
	\item Utiliser des SR complets comme seeds va être difficile, car on impose une forte contrainte sur leur nombre de match,
		  et peu de LR pourront donc être corrigés
		  Idée => Utiliser des LR complets, récupérer le fichier "tolink", et le corriger ?
\end{itemize}

\section{Jour 123}

\begin{itemize}
	\item Lors du mapping SR -> LR pour obtenir les seeds, mapper les SR ou les SR + leur RC n'amène pas au même résultat, bizarre

	\item Les free provoquent toujours des erreurs si on copie avec mlen dans algo.c, mais avec rlen ça passe
\end{itemize}

\section{Jour 124}

\begin{itemize}
	\item Préparation prochaine réunion
	
	\item Mapping des SR sur tous les LR 1D / 2D avec minScore 150 pour compter les seeds
	
	\item Téléchargement et test de Quorum (correction rapide de SR) => Peut être prometteur, car plus besoin de minScore, et seeds
		  obtenus s'alignent à 100 \%, et très rapide
		  
	\item Retravail sur l'algo reliage, car bugs avec malloc / free, encore => Tous retirés, semble ne plus poser de problèmes
	
	\item Nouveau problème : Quand les seeds sont plus disants sur les LR que sur le gen. ref., il est alors possible que les SR soient
		  distants sur le LR alors qu'ils s'overlappent sur le gen. ref.
	
	\item => Solution + amélioration : Calcul des overlaps entre les seeds avant de stocker dans le fichier
	
	\item Une fois les overlaps calculés, le premier exemple fonctionne bien plus rapidement si on laisse le 25eme seed,
		  mais celui-ci est toujours erroné
		  
	\item En fait non, si on ne met aucune condition de score, le 1er exemple bug juste au milieu, mais si on le sépare en deux, les deux parties
		  s'alignent bien à 100 \%.
		  De même, si on retire les deux seeds qui posent problème (pck autour de 900k sur le gen. ref., alors que les autres autour de 300k),
		  on obtient une seule partie s'alignant à 100 \%
\end{itemize}

\section{Jour 125}

\begin{itemize}
	\item Mapping des SR corrigés sur tous les LR 1D / 2D pour compter les seeds => Moins de LR avec seeds après correction, mais plus de seeds par LR,
		  donc plus intéressants
	
	\item Séparation des tests SR bruts / corrigés dans le PDF réunion
		  
	\item Recalcul des 64-mers des SR NaS corrigés, avec ajout des RC des SR NaS corrigés => Ne change rien aux résultats précédents
	
	\item Recherche sur comment faire la partie non reliable du 1er ex
		  => Skipper le seed non reliable (44 -> 45) du 1er exemple et continuer ne change rien, toujours impossible de relier 44 aux suivants
		  => Mapper les SR + leurs RC sur le LR ne change rien, 44 et 45 ne se relient pas
		  => Recherche de tous les 64-mers de la partie du gen. ref. qui cause l'impossibilité de reliure => Bizarre car tous présents dans
		  	 notre ensemble de 64-mers servant à générer le PgSA => L'EXEMPLE 1 DEVRAIT PRODUIRE UN LR UNIQUE, plante sûrement à cause
		  	 de la limitation du nombre d'appels récursifs
	
	\item Tests avec l'ensemble complet de SR, après correction => Ne marche pas sur le 1er exemple, car présence d'erreurs dans les seeds
	
	\item Automatisation de la séparation du LR synthétique en plusieurs parties quand certains seeds ne peuvent pas être reliés
	
	\item Recherche paramètres pblat pour faire disparaître les seeds mappés dans les 900k sur l'exemple 2
		  => Augmenter stepSize semble les faire disparaître, mais les seeds à relier sont alors plus éloignés,
		  ce qui cause une segfault car trop de backtracks
	
	\item Implémentation d'un nombre max de retours arrières + recherche d'un seuil => Problème : Semble impossible de relier des seeds
		  trop distants, à cause d'une seg fault quand trop d'appels récursifs
		  
	\item => Besoin de revoir l'implémentation de la fonction de backtracking
	
	\item Quand tous les seeds se mappent sur le LR dans l'ordre inverse d'apparition sur le gen. ref. => Pas de soucis en fait !
\end{itemize}

\section{Jour 126}

\begin{itemize}
	\item Dépression.
	
	\item Test de notre méthode (avec les SR corrigés) sur le jeu test NaS => Marche parfaitement
	
	\item Test de NaS (après galère à faire marcher) sur le jeu test NaS => Résultats un peu meilleurs, mais 6 fois + long
	
	\item Tentative de modification de l'algo pour relier => Gros bugs de partout, dur de revenir à une version qui marche
	
	\item Amélioration de l'algo pour relier, dans le cas où il n'y a pas d'ambiguité (un seed ne peut être étendue que par un seul k-mer) : plus d'appels 
		  récursifs
		  => Permet d'améliorer le temps d'exécution
		  => Besoin de retravailler un peu, dans le cas où deux seeds sont difficiles à relier (car ici, on baisse le chevauchement
		  nécessaire et on fait le backtrack à partir de l'extension maximale du seed, et non du seed lui même)
\end{itemize}

\section{Jour 127}

\begin{itemize}
	\item Ajout d'un filtre de taille max de l'extension
		  => Maintenant, il est possible de relier tout le LR du 1er test en une seule partie !
		  => Nécessité de fixer cette taille max à la taille du template ?
		  => Effectivement, semble bien marcher
		  
	\item Reprise des tests avec le filtre taille extension et comparaison nous vs NaS sur exemple LR1/2/3 => On le défonce
	
	\item Script pour tester sur un grand ensemble de LR
	
	\item Test sur M12D : 44min, nb reads / fragments = 566 (contre 602 LR initiaux) avlen = 4 906 (contre 5 197 LR initiaux), avid = 99,84 \%
		  => Notre solution marche vraiment bien !
\end{itemize}

\section{Jour 128}

\begin{itemize}
	\item Mapper les SR sur chaque LR séparément et sur tous les LR d'un coup ne produit pas les mêmes résultats
		  => Une méthode fast (tout d'un coup) et une méthode sensitive (chaque LR séparément) ?
	
	\item Programmation de fonction extension à gauche et à droite
		  => Mange à peine plus de temps (10 sec) et permet de gagner une avLen de quasiment 1k, et d'être plus long que NaS, tout en gardant
		  une excellente identité et autant de reads fragmentés, mais plus petit cumSize que NaS (quand on mappe tout d'un coup)
	
	\item Retravail sur sortie de la méthode : Les LR corrigés sont maintenant sortis sur une seule ligne
	
	\item Réunion w/ TL \& AL => Validation de la méthode, besoin de commencer à écrire article, de trouver compromis entre tout mapper et 
		  mapper séparément, étudier k-mers des SR corrigés et bruts
\end{itemize}

\section{Jour 130}

\begin{itemize}
	\item Préparation diapos pour réunion MASTODON
	
	\item Début répétition réunion MASTODON
	
	\item Test de notre méthode sur un autre jeu de données => Sur reads 1D, légèrement moins bonne qualité que NaS (-0,25 \%), mais bien meilleures
		  longueur moyenne et taille cumulée
	
	\item Reprise des tests sur M12D car résultats pas identiques à ceux notés sur le pdf
		  => On corrige moins de reads si on étend à gauche et à droite : wtf ? => En fait non, après retest ça marche, mais bizarre
		  
	\item Quand on mappe tous les SR sur tous les LR d'un coup => Si il n'y a qu'un seul seed sur un LR, alors on l'étend et on sort
		  cette extension comme correction => Permet de corriger (à 1 ou 2 près) autant de LR que NaS
		  
	\item Test de correction (sur M12D et M41D) en passant le nombre d'erreurs tolérées (dans algo.c et fichier reliage) à 0
		  => Sur M12D, 2 reads fragmentés en plus, - 50 avLen, - 6 217 cumSize, + 0,03 \% avId
		  => Sur M41D, 8 reads fragmentés en plus, - 146 avLen, - 23 422 cumSize, + 0,04 \% avId
		  => On garde
\end{itemize}

\section{Jour 131}

\begin{itemize}
	\item Test sur tous les LR ADP1 => Rapide et très efficace sur les reads 1D, long sur les reads 2D car très nombreux
		  => test arrêté, mais bonne qualité des résultats produits jusque là
		  
	\item Test sur les autres jeux de données NaS (Ecoli et Yeast) => Pareil, beaucoup trop de LR
		  => Nécessité de prendre un échantillon de ces jeux de données pour tester
	
	\item Amélioration diapos MASTODON (matinée)
	
	\item Réunion Stringmasters (Aprem)
\end{itemize}

\section{Jour 131}

\begin{itemize}
	\item Test sur Ecoli et Yeast avec des échantillons de 500 LR => Bons résultats
	
	\item Retirer la liste des k-mers déjà visités => produit des reads plus fragmentés et est + coûteux en temps
	
	\item Début écriture article
	
	\item Test tuning paramètres PBLAT pour ne plus fragmenter les reads => Ne donne rien
		  => Comment ne plus fragmenter les reads ?
\end{itemize}

\section{Jour 132}

\begin{itemize}
	\item Poursuite écriture article (Intro, PgSA overview, début notre méthode, workflow notre méthode)
	
	\item Étendre les deux seeds (à gauche et à droite) et chercher un overlap quand il est impossible de les relier
		  => Semble ne pas marcher, très peu d'overlaps
		  
	\item Correction de l'extension si seed unique : On étendait seulement à gauche
\end{itemize}

\section{Jour 133}

\begin{itemize}
	\item Recalcul des résultats des tests maintenant qu'on étend aussi à droite si seed unique => 1k + long en moyene
	
	\item Création dépot Git
	
	\item Comparaison des LR initiaux / LR corrigés => Rien de commun entre reads NaS et templates d'origine (4 k-mers)
												  => Rien de commun entre nos reaads et templates d'origine (33 k-mers)
	
	\item Poursuite écriture article (Fin explication notre méthode)
	
	\item Test en réduisant la taille de l'overlap nécessaire pour fusionner 2 seeds (63 => 32)
		  => Seulement très peu de LR fragmentés en moins, et baisse de qualité
		  => Quand overlap trop court et qu'on ne garde qu'un des deux seeds, garder le plus long (donc précédemment étendu)
		  semble permettre une meilleure qualité finale
	
	\item En fait, certains seeds qu'on tente de relier se chevauchent, d'où l'impossibilité
	
	\item Calcul des résultats NaS pour Ecoli et Yeast
\end{itemize}

\section{Jour 136}

\begin{itemize}
	\item Recherche sur comment ne plus fragmenter la correction (tuning paramètres BLAT, etc) => Pas fructueux 
	
	\item Test alignement SR -> LR avec BLASR : 5min en 8 threads avec ADP1, M12D, 50 LR avec seeds de plus qu'avec BLAT
	
	\item Test correction avec alignement BLASR (score le plus bas = meilleur) => Semble produire encore plus de LR fragmentés que BLAT
	
	\item Réunion w/ TL
	
	\item Comptage distribution des k-mers LR bruts / corrigés => La correction tend à faire apparaître plusieurs fois les mêmes k-mers
	
	\item Installation et tests de Commet (comparer des ensembles de reads par relation de similarité, 2 kmers partagés = reads similaires)
		  sur NaS et notre méthode => Permet de déterminer de quel ensemble de LR bruts vient un ensemble de LR corrigés
		  
	\item Comparaison des k-mers communs LR bruts / corrigés, avec CGkA, pour vérifier les résultats de Commet => Très peu en commun
\end{itemize}

\section{Jour 137}

\begin{itemize}
	\item Retest tuning paramètres BLAT => Rien à faire pour fragmenter moins, que ce soit en augmentant ou droppant
		  les seuils d'accuracy / qualité
	
	\item Comparer les k-mers des LR bruts / corrigés revient à comparer les k-mers des LR bruts / contigs SR, car LR corrigés
		  formés de SR
	
	\item Comparaison k-mers fréquents (> 1 fois) des LR bruts / corrigés => Pas concluant, seul la moitié des k-mers fréquents des LR bruts
		  sont fréquents dans les LR corrigés (jusqu'à 16-mers), et très peu à l'inverse
		  
	\item Tentative réinstallation BLASR, pour pouvoir sortir en BAM => Impossible, complètement impossible quoiqu'on fasse
	
	\item Vérification, après correction, on couvre autant (même un peu +) le gen. ref. que NaS
	
	\item Vérification en comparant nos reads aux reads NaS par comparaison de k-mers avec CGkA ou directement avec Commet
		  => Quasi 100 \% de similarité
	
	\item Test : Quand impossible de relier deux seeds, on essaye de relier le seed de gauche au suivant jusqu'à ce que ce soit possible
		  => Plus aucun LR fragmenté, gain de avLen mais baisse de qualité (- 0,2 \%)
		  
	\item Test : Ne considérer que les bases qui matchent (et donc ne plus appliquer de malus pour les mismatches / indels) lorsqu'on 
		  détermine quel est le meilleur de deux seeds s'overlappant => Pas concluant, produit des résultats plus fragmentés
		  
	\item Commet plante quand k = 64, mais indique que tous les LR NaS sont similaires aux notres et vice-versa 
\end{itemize}

\section{Jour 138}

\begin{itemize}
	\item Recherche des k-mers des LR bruts dans les LR corrigés => Pas la même chose que chercher les k-mers des LR corrigés dans les 
		  LR bruts ? Bizarre
		  
	\item Remodification paramètres PBLAT => Pas d'amélioration, quoique soit le paramètre modifié
	
	\item Retest d'installation de BLASR => TOUJOURS IMPOSSIBLE
	
	\item Test alignement SR -> LR avec Bowtie2 => Pas satisfaisant
	
	\item Test mapping avec BLASR et sortie SAM obsolète (M12D) => Possible de corriger plus de LR (30aine), de moins fragmenter les résultats,
		  d'obtenir une qualité très similaire (0,01 supérieure), mais un peu plus long à run + plus long à mapper
		  => Tune les paramètres pour corriger encore plus ?
		  
	\item Plus possible d'obtenir la longueur du template direct dans le fichier de mapping si on mappe avec BLASR, donc besoin de borner
		  la taille max d'une extension autrement, ou de récupérer taille du template dans algo.c, en recherchant la seq à partir de son id,
		  mais c'est long
		  
	 \item Limiter la taille de l'extension à 130 / 100 * gapSize => Pas concluant, beaucoup trop de LR fragmentés, retour à la limite = longueur tpl
	 
	 \item Test de mapping avec BLASR (M41D) => Possible de corriger plus de LR (430), de moins fragmenter, d'obtenir une qualité très similaire,
	 	   mais plus long à run + plus long à mapper
	 
	 \item Bugs de mémoire quad utilisation de BLASR en mappeur ???
\end{itemize}

\section{Jour 139}

\begin{itemize}	 
	 \item Début présentation Génoscope
	 
	 \item Test sur différentes limites de taille max extension 
	 
	 \item Correction de bugs dans l'algo (l'extension gauche provoquait des fragmentations inutiles si on bornait la taille de l'extension
	 	   avec un dérivé de la distance entre les 2 seeds, maintenant elle est fait à la fin,
	 	   et l'extension sans ambiguité pouvait provoquer la production d'un mauvais LR) => Gain de qualité
	 	   
	  \item Test tuning des paramètres de BLASR => abaisser minMatch permet de corriger un peu plus de LR,
	  		mais fragmente un peu plus
	 	   
	 \item Test tuning des paramètres de BLASR (maxScore = 0 + minMatch = 10) => Mauvais résultats, score trop haut
	 
	 \item Test tuning des paramètres de BLASR => Augmenter maxScore permet de corriger un peu plus de LR,
	 	   mais fragmente beaucoup plus
	 	   
	 \item Test BLASR, en gardant les alignements complémentaires => Permet de corriger plus de LR, tout en fragmentant moins,
	 	   quels que soient les autres paramètres
	 	   
	 \item Test BLASR, en gardant les 20 meilleurs alignements (au lieu de 10) => Pas concluant, corrige juste un peu plus
	 
	 \item Les bugs de malloc / free / etc dans l'algo venaient de BLASR qui sort des alignements de taille < 64 => Corrigé avec ajout d'un paramètre,
	 	   mais encore quelques bugs, car encore des alignements de < 64 sont sortis
	 
	 \item Test de NaS sensitive avec M12D : Au max 490 LR corrigés => On doit faire au moins aussi bien
	 
	 \item Test de NaS sensitive avec M41D => On fait mieux avec les paramètres par défaut
	 
	 \item Test tuning des paramètres avec M41D (maxScore -150 et minMatch 10) => Trop de fragments
\end{itemize}

\section{Jour 140}

\begin{itemize}
	\item Meilleurs paramètres : Garder les paramètres par défaut et conserver les alignements complémentaires, semble permettre de corriger plus
		  de LR que NaS
		  
	\item Implémentation de la récupération de la longueur du template dans son identifiant
		  => Deux fois plus rapide !
		  
	\item Amélioration des diapos (ajouts de onslide, de schémas, etc)
	
	\item Test en ne diminuant pas le nombre de backtracks en sortie de fonction, pour ne pas perdre 10min sur certains couples de seeds
		  => Permet d'obtenir sensiblement les mêmes résultats, plus rapidement
	
	\item Recalcul de tous les temps d'exécutions BLASR avec la longueur du template récupérée dans son id, et la nouvelle limitation de backtrack
		  => Même résultats, mais bien plus rapide
\end{itemize}

\section{Jour 143}

\begin{itemize}
	\item Test : Relier le seed au suivant et keep going, en utilisant BLASR => Légère baisse de qualité, production de moins de LRs,
		  pareil qu'avec BLAT
	
	\item Idée : Assemblage des k-mers fréquents (> 1) des LR avec PgSA => Peuvent à peine être étendus, ambiguïté direct
		  Mais les k-mers récupérés ont une identité moyenne de 99,46 et couvrent au max 80 \% du génome => Pas concluant
		  
	\item Idée : Aligner les LR entre eux pour en récupérer les parties correctes => Pas concluant, difficile de trouver des alignements
		  autres que d'un LR sur lui même
	
	\item LoRDEC semble être plus rapide que nous, test : Effectivement rapide, mais incapable de corriger les LR MinION
	
	\item Idée : Récupérer les "k-mers" de taille 250 des LR, les corriger, et les utiliser comme les SR de notre méthode hybride
		  => Ne semble pas concluant, Quorum ne peut pas les corriger
\end{itemize}

\section{Jour 144}

\begin{itemize}
	\item Récupération de tous les 64-mers des LR et analyse de leur qualité => 80 \%, on ne peut rien en faire
	
	\item Retest de récupération de "k-mers" de taille 250 => En fait, produit beaucoup trop de ces k-mers, fichier de 87Go
	
	\item Avec des k-mers de taille 250 apparaissant plus d'une fois : Seulement 12 LR présents, pas intéressant
	
	\item Avec des k-mers de taille 100, apparaissant plus d'une fois => Pas intéressant non plus, pas assez de k-mers,
		  puisque déjà pas assez avec k = 64
	
	\item Reprise de l'idée d'alignement des LR entre eux pour récupérer les parties correctes, avec un script permettant de trouver les
		  alignements non-self => Très long, peu d'alignements, les séquences déduites ne s'alignent pas toutes, et avId = 90 => Pas concluant
		  
	\item Tuning des paramètres de BLASR pour minimiser les LR fragmentés => minMatch à 10 semble permettre de corriger + et fragmenter -,
		  si on garde les alignements complémentaires
	
	\item Reprise du code algo.c pour déterminer quel seed prendre en cas d'overlap => prendre celui avec le meilleur score
		  produit des LR plus fragmentés et de moins bonne qualité, donc on reste comme on est, on garde le plus long
	
	\item Test en utilisant directement les k-mers comme seeds => On corrige moins de LR, pas concluant
	
	\item Test sur Yeast avec BLASR => Légère perte de qualité par rapport à BLAT, mais + de LR corrigés
\end{itemize}

\section{Jour 145}

\begin{itemize}
	\item Récupération des ensembles de LR fragmentés par la correction, et test de nouveaux paramètres pour les défragmenter
	
	\item Reprise de algo.c pour le scoring quand on fusionne 2 seeds, afin de mettre le score réel
		  Test avec choix du seed avec le meilleur score en cas d'overlap trop court => Produit d'aussi bons / meilleurs résultats qu'avant
		  et est plus logique => on garde
		  
	\item Recherche d'outils de selfcorrection de LR, et retouche de l'article
	
	\item Test de skip en cas de seeds impossibles à relier (on essaye de lier celui de gauche au prochain à droite and so on)
		  => Bons résultats sur M12D (2 LR en moins seulement), mais peut être extrêmement long
		  si le "mauvais" seed est le premier du LR, par ex sur M42D
		  
	\item Test de correction des 64-mers avec quorum => Inutile, aucun gain
	
	\item Test d'alignement des k-mers en augmentant le nombre de hits à garder => + de 1h20 en gardant 100 hits, et seulement
		  6 seeds de plus => Pas concluant
		  
	\item Test d'alignement des seeds classiques en augmentant le nombre de hits à garder => Permet de corriger un peu plus de reads,
		  mais peut amener une légère baisse de qualité (pour M41D)
		  
	\item Test d'alignement en augmentant bestn + en diminuant minMatch => Semble corriger encore un peu plus et fragmenter encore un peu moins,
		  mais 2 fois plus long à run => Pas intéressant
\end{itemize}

\section{Jour 146}

\begin{itemize}
	\item Réunion nouveaux arrivants
	
	\item Traduction diapos en anglais
	
	\item Test en diminuant maxScore => Corrige moins de LR et fragmente à peine moins
	
	\item Test en diminuant la longueur nécessaire d'un overlap pour fusionner deux seeds => Ne change rien pour M12D
	
	\item Idée : Quand on a des LR fragmentés, tenter de relier les fragments avec une nouvelle passe de l'algo => Semble marcher pour quelques LR,
		  mais pas pour la majorité => Intéressant ?
	
	\item Problème : Le nombre max de backtracks est parfois un peu dépassé => En fait non, on return juste direct un résultat négatif dans ce cas
	
	\item Test : Nos LR et les LR NaS se mappent aux mêmes endroit, à quelques bases près => On corrige bien
\end{itemize}

\section{Jour 147}

\begin{itemize}
	\item Poursuite écriture article (résultats, présentation datasets, reprise schéma, ...)
	
	\item Test en passant le seuil min d'overlap à 32 => Ne semble pas changer grand chose, car la fragmentation sera principalement causée
		  par le dépassement du seuil de backtracks ou des seeds mal mappés, mais on garde car plus logique que le seuil arbitraire de 40
	
	\item Idée : Scaffolder les assemblages fragmentés avec des reads courts => SSPACE n'y parvient pas
	
	\item Cleanup des résultats des tests sur le fichier réunion => Conversation des résultats parlant seulement
	
	\item Comparaison des runtimes pour l'alignement seulement BLAT / BLASR => BLAT est quasi instantanné, d'où l'augmentation de runtime avec BLASR
	
	\item Run de correction sur machine perso : L'exec sur serveur est effectivement plus longue à cause des processus qui runnent (57min vs
		  1h30 pour M41D)
		  
	\item Besoin de tous les LR pour réaliser l'assemblage sur ADP1 => Correction de tous les ensembles
	
	\item Optimisation : En fait, si on veut garder le seed avec le meilleur score en cas d'overlap trop court, overlapper les seeds s'ils se chevauchent
		  sur une longueur >= 31 semble produire de meilleurs résultats que si on fixe cette longueur à 63 \\
		  => Impossible de finir la comparaison car les tests plantent sur le serveur crihan, mais vrai sur les ensembles testés
		  
	\item Test assemblage nos LR vs NaS => On semble être assez mauvais, 5 contigs et seulement 1/2 du génome couvert
	
	\item NaS corrige un peu plus de reads en mode sensitive => Car il utilise tous les SR en seeds, alors qu'on utilise les SR corrigés,
		  et qu'il y en a donc un peu moins
		  
	\item Nous vs NaS : On perd seulement 0,3 \% d'identité		  
		  
	\item Comparaison NaS sur le site vs ce qu'il produit vraiment => Cohérent  
\end{itemize}

\section{Jour 150}

\begin{itemize}
	\item Test de notre méthode avec d'autres valeurs de k \\
		 128 : 487 LR dont 44 fragmentés, avLen = 4 852, cumSize = 2 629 486, avId = 99,22 \%, temps = 25 min 42 \\
		  64 : 492 LR dont 18 fragmentés, avLen = 5 449, cumSize = 2 822 627, avId = 99,96 \%, temps = 21 min\\
		  32 : 492 LR dont 23 fragmentés, avLen = 5 293, cumSize = 2 816 039, avId = 99,18 \%, temps = 13 min 18 \\
		  70 et 50 : baisse aussi
	
	\item Test assemblage de NaS_FAST => Un seul contig aussi
	
	\item Stringmasters (jour 1)

	\item Test assemblage nos LR avec les bons paramètres => Il semble être possible d'arriver à obtenir un contig unique qui couvre tout le génome
\end{itemize}

\section{Jour 151}

\begin{itemize}
	\item Stringmasters (jour 2)
\end{itemize}

\section{Jour 152}

\begin{itemize}
	\item Stringmasters (jour 3)
	
	\item Lors de la fusion de 2 seeds, le score calculé n'était pas le bon => Modification
	
	\item Tests pour obtenir mêmes résultats sur serveur / machine perso => Impossible même avec les mêmes fichiers / indexes
		  => À cause des fuites de mémoire ?
		  
	\item Test sur tous les LR d'un coup => Environ 10k LR corrigés en moins, qualité similaire, longueur supérieure, 6x plus rapide que NaS
	
	\item Comparaison correction tout d'un coup VS 1D puis 2D sur run 1 => Corriger séparément permet de corriger plus de LR, et de moins fragmenter
		  mais les résultats en termes de qualité son similaires
\end{itemize}

\section{Jour 153}

\begin{itemize}
	\item Comparaison sur tous les LR avec overlap de seeds = 63 vs overlap de seeds = 31 => 63 est très légèrement meilleur, mais + de LR fragmentés
	
	\item Script retrait des LR fragmentés du fichier final => Bug à cause des segfault dans l'algo
	
	\item Assemblage des LR corrigés run par run en ne gardant que les LR non fragmentés => Possible d'avoir un seul contig en tunant les paramètres
	
	\item Assemblage des LR corrigés run par run avec les LR fragmentés => Impossible d'avoir un seul contig
	
	\item Assemblage des LR corrigés d'un coup en ne gardant que les LR non fragmentés => Possible d'avoir un seul contig en tunant les paramètres
	
	\item Assemblage des LR corrigés d'un coup avec les LR fragmentés => Possible d'avoir un seul contig en tunant les paramètres
	
	\item Comparaison runtime assemblage : Nous = environ 1h, mais pour NaS aussi
\end{itemize}

\section{Jour 154}

\begin{itemize}
	\item Recherche de la segfault dans l'algo => À cause d'alignements de mauvaise longueur sortis alors qu'ils ne devraient pas l'être
	
	\item Création d'un script python pour filtrer les alignments trop courts
	
	\item Alignement des raw LR avec Last => Conversion en SAM incorrecte, impossible de récupérer les alignements correctement
	
	\item Test d'augmetation du paramètre besthit quand on corrige tous les LR d'un coup => Permet effectivement de corriger plus de LR
	
	\item Modifications article
	
	\item Comparaison résultats machine perso / serveur avec la correction des segfaults => Réglé
	
	\item Correction d'un autre bug de segfault dans l'algo => Car les seeds peuvent être plus longs que 1024 !
	
	\item Récupération des résultats en filtrant les alignements trop courts + correction segfault + en définissant l'overlap min à 63
\end{itemize}

\section{Jour 157}

\begin{itemize}
	\item Test assemblage avec les nouveaux jeux de LR corrigés => Résultats pire qu'avant à cause des LR fragmentés

	\item Assemblage des LR corrigés par NaS
\end{itemize}

\section{Jour 158}

\begin{itemize}
	\item Poursuite assemblage LR corrigés / LR NaS
	
	\item Remplissage des tableaux de l'article
	
	\item Assemblage des LR corrigés par notre méthode => Très mauvais résultats
	
	\item Recherche de nouveaux paramètres Canu pour assembler nos LR => Un peu mieux avec les seuils d'erreur à 0.15, mauvais avec les k-mers à 22
		  => Trouvé, marche même avec les LR fragmentés
\end{itemize}

\section{Jour 159}

\begin{itemize}
	\item Tests d'assemblage, ajustement des paramètres => Max semble être à 99,95 \% de couv avec ADP1
	
	\item Test correction + assemblage full Coli => Les LR synthétiques produits semblent ne pas couvrir suffisamment le génome de référence
\end{itemize}

\section{Jour 160}

\begin{itemize}
	\item Tests correction Coli en augmentation bestn => On couvre le génome à 100\%
	
	\item Avance écriture article (paragraphe mapping / assemblage / conclusion)
	
	\item Ajout tableaux résultats sur diapos Génoscope
\end{itemize}

\section{Jour 161}

\begin{itemize}
	\item Réunion w/ TL \& AL => Présentation des nouvelles idées, validation, rapide
	
	\item Test assemblage Coli => Impossible avec les paramètres actuels, alors qu'on couvre bien à 100 \%
	
	\item Reprise article pour le passer au format Jobim
	
	\item Test tuning des paramètres pour bien assembler ADP1 (valeur de k, nb de backtracks, taille min de chevauchement, ...)
	
	\item Il est nécessaire d'augmenter le nombre de backtracks lorsqu'on cherche des overlaps avec des k-mers plus courts
		  car sinon, le temps d'exécution est bien trop important (jusquà 20min pour un seul LR)
		  
	\item Trop baisser la taille min de l'overlap => Mauvaise qualité => 40 semble pas mal, peut être augmenter encore un peu
\end{itemize}

\section{Jours 162 - 170 (Vacaces)}

\begin{itemize}
	\item Retirer la liste des k-mers déjà visités => Plus mauvais résultats
	
	\item Test sur un jeu ADP1 pour déterminer la valeur optimale de k, et la valeur optimale du seuil overlap min
	
	\item On couvre visiblement mieux le génome de référence en choisissant des k-mers plus courts, mais pas trop, bien que la qualité
		  baisse un peu (0,1 \%)
	
	\item Ne pas autoriser un trop petit overlap min par rapport à la taille des k-mers initiaux semble améliorer les résultats
		  (moins de fragments, meilleure couverture)
	
	\item Valeur idéale de k semble être 45
	
	\item Valeur idéale d'overlap min semble être 40 (pas de grands changements avec des valeurs voisines)
	
	\item Test correction + assemblage Coli avec k = 56 => Un peu mieux qu'avec k = 64
	
	\item Test correction + assemblage Coli avec k = 42 => 7 contigs
	
	\item Test correction + assemblage Coli avec k = 45 =>
	
	\item Quand on produit un LR fragmenté, on étend à droite le dernier fragment, mais à gauche aussi ?
	
	\item La liste des k-mers visités est mal gérée dans le backtracking (quand on explore une mauvaise branche, on retire le premier des k-mers
		  erronés de la liste, mais pas les suivants, ajoutés par l'appel récursif)
\end{itemize}

\section{Jour 171}

\begin{itemize}
	\item Test modification de la gestion de la liste des k-mers visités lors du backtracking => Ne change rien
	
	\item Test RÀZ liste k-mers visités entre chaque linking de seeds => Ne change rien
	
	\item Test tuning des paramètres de Canu pour assemblage Coli
	
	\item Passer l'overlap nécessaire pour fusionner 2 seeds à 45 semble également améliorer les résultats

	\item Exposé Génoscope
\end{itemize}

\section{Jour 172}

\begin{itemize}
	\item Cleanup méthode correction, paramètres à donner à l'exécution et non à la compilation
	
	\item Script pour faire les 5 étapes d'un coup
	
	\item Parallélisation de la méthode
	
	\item Commande : ./fullTest.sh M12D.fa ADP1.fq 45 8 63 fres.fa
	
	\item Tests de fonctionnement avec la parallélisation
\end{itemize}

\section{Jour 173}

\begin{itemize}
	\item Tests d'assemblage / tuning des paramètres pour Ecoli
	
	\item Tests d'assemblage Coli sans les LR fragmentés => On est plus efficaces avec
	
	\item Retravail méthode correction => Livré à FX
	
	\item Test en modifiant le paramètre "repeat" de PgSA => Ne change rien, car non utilisé dans le code
	
	\item Test sans corriger les SR => Résultats pourris
	
	\item Test de défragmentage en fonction du résultat produit so far => Semble marcher, mais seg fault
	
	\item Recherche et correction de la segfault => Quand on skippait la première source, on faisait un realloc en donnant en param
		  la longueur d'une chaine nulle
		  
	\item Résultat du défragmentage : Permet de corriger autant de LR, et d'avoir une plus grande taille cumulée / taille moyenne
	
	\item Test du défrag sur tout ADP1 : Visiblement, provoque qq segfault ? => Car filtration des alignements non rendue générique...
	
	\item Correction de la filtration des alignements + lancement correction tout ADP1
\end{itemize}

\section{Jour 174}

\begin{itemize}	
	\item Découverte d'une erreur : On ne mettait pas bestn à 30 dans le script de correction
	
	\item Comparaison version frag + nofrag (temps, qualité, assemblage) => 
		  Sur M12D, on y gagne beaucoup au prix d'une légère perte de qualité (0,06 \%) et de 10sec de + de runtime
		  Sur tout ADP1, 	
	
	\item Recherche seuil backtrack idéal si on utilise la méthode défrag => On peut descendre au moins jusque 1 125
	
	\item Recherche valeur de k idéale si on utilise la méthode défrag
	
	\item Test déplacement incr nbBackTrack dans le code, pour être plus correct => Ne change rien, mais semble plus correct
	
	\item Test en n'augmentant pas le nombre de backtracks quand on décrémente la taille du chevauchement entre les k-mers
		  => Beaucoup trop long (probablement car on reviste des k-mers déjà visités, d'où point du dessous)
	
	\item Test en ne ràz-ant pas la liste des k-mers visités lors d'un backtrack => Ne change rien
	
	\item => Vraiment besoin d'augmenter le nombre de backtracks quand on décrémente la taille du chevauchement
	
	\item Test en ràzant la liste des k-mers visités lorsqu'on décrémente la taille du chevauchement => Plus mauvais résultats
\end{itemize}

\section{Jour 175 - 177}

\begin{itemize}
	\item Réunion w/ TL \& AL
	
	\item Encore des erreurs de segmentation dans la production de LR non fragmentés => D'où ???
	
	\item Comparaison qualité LR fragmentés / non fragmentés => Les non fragmentés sont un peu moins précis,
		  mais la perte est faible
	
	\item Comparaison assemblage LR fragmentés / non fragmentés sur ADP1 => On ne produit pas un seul contig avec les
		  LR non fragmentés avec paramètres par défaut, mais on s'en approche beaucoup (deux très courts contigs en +),
		  et couverture toujours a 99,95
	
	\item Implémentation nb max de seeds skippés
	
	\item Implémentation extension par k-mer le + fréquent en 1er => Impossible, car on indexe les k-mers et non les reads
	
	\item => Possible de simuler ça avec une table de hash / whatever ?
	
	\item Légère retouche article
	
	\item Lancement test correction sur ADP1 avec la version modifiée (1125 ol + 10 skips seeds max) du linker => 21h à tout corriger,
		  seulement 230k de bases en moins, qualité / avLen similaires => Super intéressant
	
	\item Test assemblage ADP1 avec version modifiée linker => Résultats très similaires à la version où on teste tous les reliages
		  possibles
	
	\item Test assemblage ADP1 en ajustant les paramètres => Un seul contig, mais toujours pas 100\%
	
	\item Recherche valeur de k idéale pour l'assemblage non fragmenté => Aucun pic observé
	
	\item Lancement correction Coli avec k = 64, car pas de paramètre vraiment meilleur
\end{itemize}

\section{Jour 178}

\begin{itemize}
	\item Suite de la recherche de valeur de k idéale pour l'assemblage non fragmenté => Aucune valeur ne se dégage vraiment
	
	\item Retouche article (TODO: CITER PARALLEL)
	
	\item Installation et tests d'autres outils de correction (Colormap et Jabba) \\
		  => Jabba est extrêmement rapide, corrige à peu près autant de reads que nous, avec une bonne identité,
		  mais produit des assemblages de très mauvaise qualité
		  => Colormap est 3 fois plus rapide que nous, mais produit une correction de mauvaise qualité
	
	\item Recherche de paramètres pour bien assembler ADP1
	
	\item Assemblage Coli sans reads fragmentés, paramètres par défaut => On est meilleur que Jabba, proche du contig unique
	
	\item Lancement correction Yeast non fragmenté
\end{itemize}

\section{Jour 179}

\begin{itemize}
	\item Suite de la recherche de valeur de k idéale pour l'assemblage non fragmenté
	
	\item Recherche de paramètres pour bien assembler ADP1 / Coli
	
	\item Optimisation code linking seeds + correction d'un bug post-optimisation
	
	\item Correction du bout de code causant probablement la segfault dans le traitement des seeds (lors du calcul de l'overlap entre deux seeds
		  qui se suivent)
	
	\item La version optimisée est extrêmement lente sur certains LR, wtf ? => Car j'avais retiré le nb max de backtracks...
	
	\item La version optimisée fonctionne et produit les mêmes résultats
	
	\item Retouche et annotation de l'article
	
	\item Demander en réunion : Besoin de préciser error correction à chaque fois ?
	
	\item TODO : Répétition pour notre méthode dans intro / son chapitre
\end{itemize}

\section{Jour 180}

\begin{itemize}
	\item Test passage du minOverlap à KLEN - 10 => Produit de plus mauvais résultats
	
	\item Test en mode full DBG => Semble donner meilleure avLen, meilleure cumSize, meilleure cov, plus faible identité
							   => Problématique ?
							   => Vient du fait que quand on arrive au bout d'un chemin pour lequel on a plus de chevaucehment de k-1,
							   	  on poursuit sur ce chemin avec des chevauchements de k-2, au lieu de backtrack vers les autres
							   	  chemins qui ont des chevauchements de k-1

	\item Grosse refonte article (répétitions, passage en mode DBG / OL graph)
	
	\item Test valeur de k idéale sur 500 LR Ecoli => Ne s'accorde pas avec la valeur trouvée pour ADP1 (91 ou 50)
	
	\item Recherche d'un consensus de valeur idéale ADP1 / Coli => Valeur située entre 55 et 60
	
	\item Trouvé une erreur dans le code ? => Ne change rien sur le jeu testé, mais pouvait être problématique dans certains cas
	
	\item Lancement full correction Coli avec k = 55, semblant être optimal
	
	\item Test assemblage sans l'étape de correction, à la main => Mêmes résultats que quand on corrige aussi
\end{itemize}

\section{Jour 181}

\begin{itemize}
	\item Fin recherche consensus valeur idéale de k => k = 54 ou 55 sur ADP1 / Coli
	
	\item Recherche valeur idéale sur 500 LR Yeast => par consensus, 55
	
	\item Retouche article (résultats colormap / jabba, conclusion, paragraphe paramètres)
	
	\item Colormap corrige très mal, et Jabba corrige bien, mais couvre peu le génome de référence
	
	\item Idée : Si après le nombre donné de skips, il reste des seeds => Les relier quand même et fragmenter ?
\end{itemize}

\section{Jour 181-183}

\begin{itemize}
	\item Étude résultats mapping Coli avec k = 55, et comparaison avec k = 64 => k = 64 a une meilleure taille cumulée, le reste est similaire
	
	\item Étude assemblage Coli avec k = 55 => Meilleur avec k = 64...
	
	\item Réunion w/ TL \& AL
	
	\item Retrait des fichiers textes temporaires, et récupération des seeds à lier directement dans un tableau, afin de pouvoir fragmenter et forcer
		  le reliage
	
	\item Test de l'optimisation précédente => Bug => Recherche et correction du bug
	
	\item Implémentation fusion skipping + fragmentation => Améliore encore les résultats par rapport à la version précédente
	
	\item Recherche nombre de skips idéal => 5 semble être pas mal
	
	\item Nouvelle recherche taille k idéale => Résultats semblent cohérents avec ceux observés précédemment au niveau
		  des variations de valeurs, difficile de trouver mieux que 64, 55 diminue trop la qualité même s'il augmente la couverture, 
		  la taille totale,
		  et la taille moyenne, et 76 diminue trop la couverture, la qualité, et la taille totale, même s'il augmente la taille moyenne
		  
	\item Lancement correction full Ecoli k = 64, avec la nouvelle méthode => Seulement 2 contigs !
	
	\item Recherche paramètres pour mieux assembler
	
	\item Test full Coli avec k = 75 => L'assemblage produit est mauvais, quels que soient les paramètres de Canu
	
	\item Test full Coli avec k = 55 => Tué sans faire exprès...
	
	\item Retouche article, ajout du graphe + du schéma de seed skipping, fusion tableaux 1D / 2D
	
	\item Lancement NaS fast ADP1 => interminable
\end{itemize}

\section{Jour 184}

\begin{itemize}
	\item Kill de NaS fast => Toujours rien après 3 jours de run
	
	\item Lancement Colormap sur Ecoli + récupérations des résultats
	
	\item Relancement notre méthode sur Coli, k = 55, car process tué par accident...
	
	\item Étude résultat Colormap sur ADP1 => Le OEA ne change rien, mais bouffe plus de temps
	
	\item Retouche schémas seed skippings, retouche article, reformulation, ...
	
	\item Relancement Colormap sur ADP1
	
	\item Vérification bibliographie
\end{itemize}

\section{Jour 185}

\begin{itemize}
	\item Récupération résultats Coli k = 55, et test d'assemblage => Plus mauvais que k = 64
	
	\item Lancement test Coli k = 60
	
	\item Récupération résultats CoLoRMap ADP1
	
	\item Réunion w/ AL => Vérification article, tout est bon, plus qu'à synthétiser un peu
	
	\item Retouches article, remise en forme, synthèse, reformulation, ...
	
	\item Lancement CoLoRMap sur Yeast
\end{itemize}

\section{Jour 186}

\begin{itemize}
	\item Comparaison Coli k = 60 et k = 64 => À paramètres égaux, k = 64 produit un meilleur assemblage
	
	\item Tests sur les paramètres de Canu pour n'obtenir qu'un seul contig
			Augmenter un peu l'estimation de la taille du génome => Ne change rien
			Trimmer avant l'assemblage, sans paramètres => Pas de changement pour ADP1, ni pour Coli
			Trimmer avant l'assemblage, avec paramètres => Aucun changement non plus

	\item Lancement test Coli k = 68 => Couvre moins que 64 quand on aligne autant de reads => Abandon avant la fin
	
	\item => Lancement test Coli k = 65 
	
	\item Reprise schéma seed skippings et passage en N&B
	
	\item Récupération de la couverture (en \%) de Yeast par les LR avec Last, puis conversion en sam, puis depth
		  => Les résultats (pour l'identité) du sam produits sont erronnés, mais semblent correct pour le depth
		  (on couvre bien tout ADP1 et tout Ecoli en vérifiant avec cette technique)
		  
	\item Récupération du coverage (en x) des 3 jeux de données LR => Que mettre pour Yeast ?
	
	\item Tests intensifs sur les paramètres de Canu (augmentation / baisse peu à peu de taille k-mer, error rate, et merSize)
\end{itemize}

\section{Jour 187} 

\begin{itemize}
	\item Poursuite des tests sur les paramètres de Canu => Pas concluant, 2 contigs avec Coli, k = 64 quoiqu'il arrive
	
	\item Relecture complète article et annotation des points à vérifier à la prochaine réunion
	
	\item Récupération résultats CoLoRMap sur Yeast
	
	\item Récupération runtimes Jabba 16 procs sur tous les jeux de données + résultats sur Yeast
	
	\item Lancement test Coli 63 sur machine perso 
	
	\item Comparaison assemblage Coli 64 / Coli 65 => 64 est toujours meilleur...
	
	\item Lancement test Coli 64 avec 3 seeds skip max => Couvre moins
	
	\item Lancement test Coli avec 1500 backtracks
\end{itemize}

\section{Jour 188 - 190}

\begin{itemize}
	\item Récupération Coli 63 + Comparaison assemblage Coli 64 / Coli 63 => Toujours meilleur avec 64....
	
	\item Comparaison de coverage (en x) de nos jeux de données => Le calcul en R fait un peu n'importe quoi
		  (indique un couverture de 37 pour NaS fast sur Coli, alors que ce n'est pas le cas)
	
	\item Récupération Coli 1500 backtracks + comparaison Coli 1125 backtracks => Produit de meilleures métriques (avLen, cumSize, id un
		  peu plus faible) mais un plus mauvais assemblage (reads chimériques avec plus de BT)
	
	\item Réunion w/ TL \& AL => Relecture de tout le papier, correctifs + essayer d'étendre en dehors des templates
		  
	\item Test en étendant en dehors des templates => Permet d'obtenir des SLR bien plus longs, qui s'alignent bien, et couvrent mieux
	
	\item Lancement 1125 BT sur Crihan, 1000 BT machine perso, avec extensions en dehors des templates
		  => Les deux sont très similaires, 1125 semble un peu mieux
	
	\item Test d'assemblage avec extension en dehors des templatess => Très mauvais résultats sans trimming
		                                                            => Pareil avec trimming...
		                                                           
	\item Recherche de paramètres pour correctement assembler les LR étendus en dehors des templates :
			=> Diminuer error rate : N'améliore rien
			=> Augmenter error rate : Semble un peu mieux, mais toujours trop de contigs
			=> Paramètres par défaut : N'améliore pas non plus
		  => DONC => Étendre en dehors des templates = mauvaise idée ? Bizarre...
		  
	\item Test assemblage SLR étendus avec 1000 BT => Mauvais résultats aussi
	
	\item Récupération temps premières étapes de Coli
		                                                           
	\item Lancement full Yeast en étendant seulement jusqu'au bout des tpl
	
	\item Encore des segfault dans le code du linker => Du au mauvais filtrage des courts alignements (on ne comptait pas len de l'alignement)
		  => Corrigé, et recorrection de Coli 64 sur machine perso, voir si on peut avoir un meilleur assemblage
		  => Toujours des segfaults dans Yeast
		  => Parce qu'on a créé le fichier de seeds à partir du fichier d'alignements erroné,
		  	 et que HG-CoLoR va chercher des seeds qui n'existent plus dans le nouveau fichier, car aucune segfault pour Coli
\end{itemize}

\section{Jour 191}

\begin{itemize}
	\item Coli sur machine perso ne donne pas les mêmes résultats que Coli sur machine Crihan => Recherche d'où ça vient
		  => Les SLR ne s'alignent pas aux mêmes endroits entre les deux versions, même s'ils sont identiques, wtf ???
		  => Très peu de reads semblent être différents entre les deux versions
		  => A cause du nouveau filtrage ? Semble que non...
		  => Test sur un LR avec les deux différents types de filtres => Pas à cause du filtrage, même résultat dans les deux cas
		  => RÉPONSE => Car le linker utilisé avant, pour générer l'ancien fullcoli64, était un peu différent, impossible de trouver où
		  
	\item Tests d'assemblage de Coli sur machine perso => Catastrophique avec le jeu Coli corrigé sur machine perso
			=> À cause des paramètres ?
	
	\item Modifications sur article (retour à version extension jusqu'au bordures des templates + qq correctifs / reformulations)
		  
	\item Recalcul des coverage des LR initiaux avec samtools depth + average de colonne 3
	
	\item Lancement full correction ADP1 sur machine perso
		  => Encore des segfaults, wtf ? => Sûrement dû à la modification de correctRead pendant l'exécution
		  => Première chose à faire : Récupérer les LR qui n'ont pu être traités à cause de la modif, et les corriger
		  	 (script déjà prêt, devrait être rapide)
	
	\item Même avec le bon ensemble de SLR et les bons paramètres, impossible de bien assembler Coli 
		=> Car le dnadiff sur machine perso de marche pas
		=> Besoin d'assembler sur machine Crihan
	
	\item Test assemblage SLR étendus au delà des templates => Cohérent avec les résultats précédents, mauvais assemblage
	
	\item Test assemblage SLR obtenus sur machine perso => Mêmes résultats qu'avec l'ancien jeu SLR Coli
\end{itemize}

\section{Jour 192}

\begin{itemize}
	\item Correction des LR ADP1 manquants : Seulement 2 corrigés de plus
	
	\item Recherche d'où viennent les segfault sur le petit jeu ADP1 => Car allocation impossible à un moment,
		  si le read à étendre est déjà trop grand => Passer au malloc pour version finale ?
	
	\item Assemblages Coli / ADP1 sur machine Crihan, recherche de consensus
		  => 3 contigs et 99,99 de cov (0.08 partout) ou 2 contigs et 99,95 de cov (0.085 partout) pour Coli
		  => Possible d'avoir un seul contig a 99,99 pour ADP1 (0.07 partout)
		  => Possible d'arrêter avant la fin du consensus pour obtenir le nombre de contigs, gagne du temps
		  => Chercheur une valeur entre 0.07 et 0.085 pour avoir l'optimal pour les deux 
		  	=> 0.075 ne marche pas, toujours 3 contigs pour Coli, et 2 pour ADP1 => Modifier chaque paramètre séparément ?
		  
	\item Ajouts résultats ADP1 dans le tableau
	
	\item Ajoute des \% de LR alignés / sans erreurs dans le tableau
	
	\item Discussion sur les résultats alignements
	
	\item Restructuration papier, sur la partie PgSA
\end{itemize}

\section{Jour 193}

\begin{itemize}
	\item Différence entre trim-assemble et assemble => Aucune, juste assemble est même légèrement meilleur
	
	\item Légères retouche de perfectionnement sur l'article
	
	\item Suite et fin de la recherche de consensus sur les paramètres de Canu pour bien assembler ADP1 ET Coli (Toute la journée)
		  => Possible d'avoir 2 contigs pour Coli avec error rate = 0.0825 et merLimits = 0.9955
		  => Possible d'avoir un contig pour ADP1 avec error rate = 0.0800 et merLimits = 0.9975
		  => Avec error rate = 0.08125 et merLimits = 0.9965 => Pas de consensus, les deux se plantes, quelle que soit la valeur de k (en train d'être fait)
		  
		  => Baisser les merLimits à 0.9925 permet d'avoir 2 contigs pour Coli avec errorRate a 0.08 et merSize à 15
		  => Pour ADP1, merLimits à 0.9925 et merSize à 15 ne permet pas d'obtenir 1 seul contig, que errorRate soit 0.08 ou 0.075
		  => Inutile de fouiller d'avantage, pas de consensus sur errorRate
		  
		  => Baisser les merLimits a 0.99 ne permet pas plus de trouver un consensus sur les autres paramètres
		 
		  => Impossible de trouver un consensus, on corrige chaque jeu de données avec son propre errorRate, en les précisant dans le papier
		  
	\item Assemblage de tous les ensembles de LR ADP1 / Coli avec toutes les méthodes
	
	\item => On est bien meilleur que toutes les autres méthodes, sauf NaS
\end{itemize}

\section{Jour 194}

\begin{itemize}
	\item Assemblage Yeast avec toutes les méthodes => Mauvais avec HG-CoLoR
	
	\item Recherche des meilleurs paramètres pour HG-CoLoR => Pas de grande amélioration
	
	\item Réassemblage Yeast avec les autres méthodes
	
	\item Remplissage tableau assemblage
	
	\item Discussion sur les résultats d'assemblage obtenus
\end{itemize}

\section{Jour 195}

\begin{itemize}
	\item Modifications article (CoLoRMap n'assemble que Coli)
	
	\item Relecture article
	
	\item Correction biblio + soumission article
	
	\item Test de résolution du bug en cas de SLR trop long avec un malloc => Règle le problème
	
	\item Relancement de correction sur ADP1 / Coli / Yeast avec le problème de segfault réglé
\end{itemize}

\section{Jour 198}

\begin{itemize}
	\item Programmation options bash
	
	\item Programmation options dans le linker
	
	\item Tests de fonctionnement => Good
	
	\item Cleanup scripts pour livrer à FX (=> scripts / exec finaux dans test.../long.../FX)
	
	\item Modification tableau assemblages article (expected contigs de Yeast était à 1 au lieu de 30 pour CoLoRMap) + correction 2 typos
	
	\item Rerun assemblage ADP1 et Coli NaS pour vérifier, car résultats bizarres dans le tableau => En fait, ils étaient bien corrects
	
	\item Màj dépot git => Impossible, trop de fichiers, trop gros
	
	\item Besoin de revoir la fin de discussion assemblage demain (parce que bizarre de passer de pb NaS à ccl sur la viabilité des SLR)
		  => changer les 2 paragraphes, plus commencer le 2 par Surprisingly, however ... Yet, the simple fact of... ?
		  + Besoin de revoir la fin de conclusion => Dire que NaS n'est vraiment mieux que HG-CoLoR que sur Yeast ?
	
	\item Lancement correction Coli sur machine perso, avec le nouveau linker (qui malloc le res peu à peu) => Ne change rien
\end{itemize}

\section{Jour 199}

\begin{itemize}
	\item Recherche comment utiliser la library PgSA
	
	\item Création d'un makefile propre utilisant la librairie PgSA
	
	\item Cleanup de code, partie 1
	
	\item Toujours une erreur dans le Makefile, ne compile pas seedsProcessing => Car un fichier du meme nom était dans le PWD => Réglé
	
	\item Test d'installation avec le Makefile, sur machine perso => Ne marche pas... Apparemment à cause de l'ordre des paramètres de compil	
			=> Réglé, si on compile tout PgSA sur chaque machine et qu'on inclue pas la librairie
\end{itemize}

\section{Jour 200}

\begin{itemize}
	\item Création README correct
	
	\item Renommage des fichiers PgSAtests related
	
	\item Test d'installation et de run de HG-CoLoR sur machine perso => Problème : ne corrige plus M12D
		  => A cause des noms de templates incorrects
		  => Fonctionne bien		  
		  
	\item Déploiement HG-CoLoR (galère pour commit avec le bon compte)
	
	\item Résolution conflit git pour avoir un backup des fichiers de thèse => Maintenant facile, juste à add les dossiers à update peu à peu
	
	\item Update articles avec nouvelles valeurs pour Yeast => L'assemblage est moins bon, il faudra revoir les paramètres
		  de Canu pour la soumission finale
	
	\item Resoumission article
	
	\item Retest de la version déployée de HG-CoLoR sur machine perso, sur M12D => Marche nickel
\end{itemize}

\section{Jour 201}

\begin{itemize}
	\item Lecture Rastack => Semble ne pas être dispo en ligne ?
\end{itemize}

\section{Jour 202}

\begin{itemize}
	\item Optimisation code HG-CoLoR :
			- passage en vecteur plutôt qu'en tableau de structs 
			  => donne des résultats différents d'avant : car la comparaison entre 2 seeds est booléennes, et était entière avant
			  
			- passage en full string c++ plutôt qu'en char*
			  => presque bon, sûrement une erreur d'indicage qui traine
			  => L'erreur vient de la fragmentation des SLR => Problème réglé
\end{itemize}

\section{Jour 205}

\begin{itemize}
	\item Installation et test de gkampi => permet de compter des k-mers espacés
	
	\item Modifications sur PgSA pour pouvoir rechercher un ensemble de k-mers dans un index
\end{itemize}

\section{Jour 206}

\begin{itemize}
	\item Test recherche k-mers espacés des LR dans les SR => Pire que les kmers contigus
			=> Parce que gkampi n'extrait pas les k-mers espacés de la façon dont on a besoin
	
	\item Téléchargement de Yeast Pacbio, et lancement de HG-CoLoR => Beaucoup trop de LR, pas viable
	
	\item Recherche d'un autre ensemble de LR PacBio Yeast => Trouvé un jeu assez similaire au précédent
			=> Test qualité => Meilleur que le jeu d'avant (62\% vs 45\%)
	
	\item Déploiement de la version c++ de HG-CoLoR sur machine Crihan + lancement test sur Yeast voir si il y a des bugs => A l'air bon
	
	\item Lancement HG-CoLoR sur Yeast PacBio
\end{itemize}

\section{Jour 207}

\begin{itemize}
	\item Recherche Spaced SA dans LAST => Emplacement trouvé, possible de modifier et d'extraire le résultat en fonction du pattern donné
	
	\item Recherche calcul SA dans GkA => Emplacement trouvé, mais impossible de chercher un ensemble de k-mers provenant d'autre reads, car les
		  requêtes se font par position
\end{itemize}

\section{Jour 208}

\begin{itemize}
	\item Difficile d'utiliser GkA / PgSA pour la recherche de k-mers espacés avec Spaced-SA, car on ne sait pas comment
		  sont traîtées les requêtes, contrairemet à GkA
		  
	\item Test recherche k-mers espacés dans SSA => De toute façon, LAST calcule en fait mal le SA, même non espacé

	\item Extraction de k-mers des LR avec contrainte sur le nombre min => Donne des k-mers corrects, mais bien trop peu nombreux
	
	\item Test de comparaison 64-mers LR vs 64-mers SR, contigus et espacés + cumSize des k-mers communs
		  => Pas concluant, on ne trouve pas assez de k-mers communs, et le cumSize SR vs commun est clairement dominé par les SR
		  
	\item Même test avec des 16 mers => Pareil, le cumSize est dominé par les SR
	
	\item Test de comparaison 16-mers LR vs 16-mers SR en ajoutant tous les k-mers trouvés (espacés et non espacés) dans un même fichier
		  => On arrive à des choses un peu plus intéressantes
\end{itemize}

\section{Jour 209}

\begin{itemize}
	\item Test comparaison 32-mers LR vs 32-mers SR => Résultats pourris avec les k-mers espacés
	
	\item Segfault dans HG-CoLoR => Recherche de la cause
			=> Dépassement du cota disque à un moment, lors de la filtration des alignements
			=> Test sur le LR le plus long, voir si à cause d'un débordement de la taille de la pile => Non, passe bien
			=> Relancement de toute la correction Yeast PacBio
			=> EN FAIT => Beaucoup trop de LR à corriger, beaucoup trop long, pas viable
					   => Besoin d'un nouveau jeu de LR
					   
	\item Lancement correction ADP1 sur machine perso voir si segfault aussi => Passe sans problèmes
	
	\item Début calcul union 16-mers espacés avec un gap de len variable au milieu (pour l'instant, LR dans SR)
	
	\item Indexation de tous les 64-mers des LR (PgSA)
\end{itemize}

\section{Jour 212}

\begin{itemize}
	\item Fin calcul union 16-mers espacés LR dans SR => On capture quasi tout !
	
	\item Calcul union 32-mers espacés LR dans SR 
	
	\item Cleanup de code final HG-CoLoR 
			=> Gain de temps en virant les drawData
		    => Bug incompréhensible avec le outSrc
\end{itemize}

\section{Jour 213}

\begin{itemize}
	\item Fin calcul 32-mers espacés LR dans SR => Pas terrible
	
	\item GkAmpi marche bien avec des k-mers espacés
	
	\item Quand on cherche les 16-mers de ADP1 dans l'index des 64mers, on ne trouve pas tout...
			=> Test en construisant l'index avec les RC en plus des forward => Améliore à peine
			=> Il y avait en fait une erreur dans le code, pas de màj de found quand on recherchait le RC
			=> Permet de retrouver les résultats de l'index avec les RC, mais ne trouve pas tout
			=> => => car certains reads sont plus petits que 64, on perd juste l'info de ceux là => ok 
			=> En cherchant les 16 mers, dans un index des 16 mers => on a bien tout
			
	\item Besoin de rerun tous les tests faits jusqu'alors, en construisant un index des SR pour chaque k
	
	\item Début recalcul 16-mers espacés LR dans SR
\end{itemize}

\section{Jour 214}

\begin{itemize}
	\item Fin recalcul 16-mers espacés LR dans SR => On identifie presque tout
	
	\item Début recalcul 32-mers espacés LR dans SR
	
	\item Bug avec l'index des 64-mers des LR
			=> Construction de l'index des 32mers
			=> Test avec cet index => Toujours impossible
			=> Test avec l'index des 16 mers => Toujours pas
	
	\item Énorme bug incompréhensible sur HG-CoLoR, on ne retrouve jamais les mêmes résutlats
			=> Comparaison point par point avec version Crihan : Tous les fichiers sont pareil
			=> Aucune putain de version ne donne le même putain de résultat
			=> Pas de SLR fragmentés sur machine Crihan, wtf => en fait si en réalignant 
			=> Pas le même résultat en lançant 2 fois de suite la correction sur les mêmes fichiers => ?????????????????????
			=> Dû au mapping avec BLASR, qui ne sort jamais le même fichier, vu que Quorum ne sort pas les reads dans le même ordre à chaque fois
				=> NON, les fichiers sont exactements les mêmes à chaque fois ???????????
			=> Quand on garde les mêmes fichiers tmp et qu'on lance 2 fois de suite la gen de SLR, on obtient la meme chose
			=> Ok, résultats différents car le fichier d'alignement n'est pas sorti toujours dans le même ordre,
			   donc parfois problème quand on compare 2 seeds avec "<", l'un pouvant être inclus dans l'autre, et sauté ou pas, en fonction de l'ordre
			   d'apparition (n'était pas possible avant, car on avait une comparaison en 3 valeurs, en C)
			   => Résolu en faisant un sort du fichier d'alignement avant traitement par le linker, on obtient bien alors, toujours le même résultat
			   => Test de cette modif sur Crihan et sur machine perso => Good
			   => Le sort prend environ 6 secondes pour ADP1 sur Crihan, et 2 sur machine perso, correct
			=> A pris tout l'aprem
			  
	\item Test en passant curback par référence, en gardant les mêmes fichiers tmp qu'un test précédent
			=> ne marche pas du tout, se bloque et provoque des infinite runtimes
			=> retour à la version pointeur
	
	\item Test index 16-mers LR en utilisant les k-mers canoniques => Toujours segfault
\end{itemize}

\section{Jour 215}

\begin{itemize}
	\item Fin recalcul 32-mers espacés LR dans les SR
	
	\item Test relancement HG-CoLoR sur les 200k LR PacBio => Pas assez d'espace disque ?
		  => A cause du sort du fichier d'alignement pour avoir le même res à chaque fois
		  => Abandon de l'idée, car peut demander bcp trop d'espace disque
		  => Test sans le sort
		  => Beaucoup trop long
		  
	\item Test en coupant le fichier en 5 => Toujours trop long, 8h pour corriger 1500 LR...
	
	\item Passage des derniers char* de HG-CoLoR en string => Au final, besoin de rester en char* pour
		  pas mal de fonctions => retour à l'ancienne version
		  => Retest => marche bien
		  => Redéploiement sur Github + retest => Good
\end{itemize}

\section{Jour 216}

\begin{itemize}
	\item Correction bcp trop longue avec Yeast PacBio => À cause de la technologie ?
			=> Téléchargement d'un jeu Ecoli PacBio + test
			=> Marche bien, rapide, mais l'assemblage est pourri : À cause des LR de base ?

	\item Recherche d'un nouveau jeu Yeast avec moins de LR => Semble difficile à trouver,
		  car bcp trop de LR avec PacBio, donc traitement bcp trop long
	
	\item Recherche sur comment chercher k-mers SR dans LR
\end{itemize}

\section{Jour 219}

\begin{itemize}
	\item Férié
\end{itemize}

\section{Jour 220}

\begin{itemize}
	\item Test construction et recherche dans l'index des 64-mers LR sur machine perso
			=> demande trop de RAM
\end{itemize}

\section{Jour 221}

\begin{itemize}
	\item Recalcul de l'index des 16-mers et retest sur machine Crihan => Bug
	
	\item Test construction et recherche dans l'index 16-mers sur machine perso => Bug aussi
			=> Le bug vient donc bien de PgSA
\end{itemize}

\section{Jour 222}

\begin{itemize}
	\item Test sur HG-CoLoR : Des trucs dans les log errlog ? Non, good, rien à part les sorties de BLASR / PgSA
	
	\item Test en séparant l'index des LR en 2 => Passe bien sur les deux parties
	
	\item Début de calcul des 16 mers des SR dans les LR avec les 2 index
\end{itemize}

\section{Jour 223}

\begin{itemize}
	\item Fin recherche des 16-mers des SR dans les LR avec les 2 index => Suffit à identifier tous les k-mers !
	
	\item Avec seulement les 16-mers jusqu'à 3 trous => Seulement la moitié des k-mers
	
	\item Avec seulement les 16-mers jusqu'à 5 trous => Seulement 2/3 des k-mers
\end{itemize}

\section{Jour 226 reprise}

\begin{itemize}
	\item Vérification : Les k-mers des SR trouvés dans les LR sont ils bons (présents dans les SR) ? => Non, la plupart
		  sont mauvais, normal car on introduit des dels quand on les extrait
		  => pas viable
		  
	\item Test extraction 32-mers espacés des LR, et conservation de ceux avec un certain nb occ, après union des fichiers
		  => Impossible de les unir simplement, car après extraction, chaque k-mer n'apparait plus qu'une fois
		  => De toute façon, il semble qu'il y ait peu de k-mers communs
		  (Ici, on voulait d'abord extraire, puis fusionner, et déduire les fréquents après)
		  
	\item Test lancement HG-CoLoR Yeast PacBio avec bestn = 10 => + de 1k / heure !
\end{itemize}

\section{Jour 227}

\begin{itemize}
	\item Recherche de similarités entre les 16-mers des reads longs sur un run unique de ADP1 ?
		  => Non, on perd trop d'info par rapport au jeu complet
		  
	\item Recherche des 16-mers espacés fréquents (>= 5) séparément, puis union des fichiers
		  (Ici, on prend les fréquents de chaque sous ensemble, et on fusionne après)
		  => Donne beaucoup de 16-mers une fois l'union faite, mais peu sont présents dans les SR
		  => Les seeds avec + de trous semblent ne pas apporter d'info en plus (pour 1111011110111101111)
		  => Recherche des 16-mers extraits dans le gen ref : Toujours enormément de 16-mers erronés (15M),
		  mais on capture presque tous les 16-mers du gen ref (2 tiers)
		  
	\item Étude du nombre de 16-mers, 32-mers, 64-mers des SR (raw / corrigés) et du gen ref 
		  => On doit effectivement s'approcher le plus possible du nombre de k-mers du gen ref
			
	\item Extraction des 32-mers fréquents et contigus (=> 5) pour pouvoir les aligner sur le gen ref
		  => -L 5 = trop violent, passage de 3M de 16-mers récupérés à 150k de 32-mers
		  => -L 3 = Passage de 3M à 1M, les 32-mers fréquents extraits sont pour 2/3 présents correctement dans le gen ref,
		  	  pour le reste, ils s'alignent à 95.8 \% (99.76\% en global)
		  => Quand on passe aux k-mers espacés (même avec 1 seul gap), presque aucun ne se trouve dans le gen ref,
		  	 mais ils s'alignent à 99.74\% en global
		  => Quand on extrait tous les 32-mers : 98,26 \% en global => mauvais
\end{itemize}

\section{Jour 228}

\begin{itemize}
	\item Poursuite études des 32-mers SR / LR / gen ref
		  => 32-mers des SR bruts : 99.54\%
		  => 32-mers des SR corrigés : 99,99\%
		  => On est donc encore bien en dessous de la qualité attendue, même en conservant uniquement les 32-mers fréquents
		  
	\item Test de correction des 32-mers fréquents (contigus & 1 gap au milieu) avec Quorum => Aucune amélioration
	
	\item Test extraction de 32-mers espacés avec des seeds random (trous parsemés) => Très mauvais résultats
	
	\item Test : N'utiliser qu'un trou mais le déplacer ne donne pas les mêmes résultats en fonction d'où il est placé,
		  et semble permettre de sortir pas mal de bons k-mers
	
	\item Recomptage k-mers SR raw / corr + gen ref, en canonique, pour pouvoir mieux comparer aux résultats des unions
		  => En fait, il y a il y a pile le bon nombre de k-mers dans les SR
	
	\item Création script pour extraire tous les k-mers avec un trou qui se déplace => Recodé en python
	
	\item Test extraction de tous les 32 mers espacés possibles avec un trou, -L = 4 => Fail, lancé avec les mauvais paramètres (-L 1)
\end{itemize}

\section{Jour 229}

\begin{itemize}
	\item Re-extraction de tous les 32-mers espacés possibles avec un trou => Trop peu de k-mers présents dans le gen ref,
		  + trop mauvais qualité
		  
	\item Extraction avec -L 5 => Encore pire niveau identité 
	
	\item Début préparation diapos
	
	\item Extraction avec -L 10 => Trop peu de k-mers, très peu dans le gen ref + identité encore pire
\end{itemize}

\section{Jour 230}

\begin{itemize}
	\item Poursuite préparation diapos
	
	\item Correction d'une ereur dans le schéma du graphe hybride dans le papier HG-CoLoR
	
	\item Test installation GkAmpi sur Crihan => Toujours impossible
	
	\item Étude : Comment LoRMA adapte LoRDEC ? => Plusieurs itérations de correction avec les k-mers des LR,
		  en ne gardant que ceux qui apparaissent un cetrain nombre de fois, et en augmentant k à chaque itération
		  => Jouable car par de SLR synthétiques, pas possible avec HG-CoLoR
		  
	\item Idée : Extraire les bons 16-mers (paramètres à trouver) puis synthétiser des bons k-mers plus grands
		  avec notre graphe ou un assembleur ?
		  => Avec un assembleur non, à voir avec notre graphe
		  
	\item Idée : Extraire les k-mers fréquents après correction des SR ?
		  => Permet de réduire les mauvais k-mers, mais réduit aussi le nombre de bons (Les rev comp ? Possible des les retrouver ?)
		  		=> Non, pas possible de les retrouver
		  => Mais une petite limite (4-5) permet de réduire le nombre de mauvais k-mers tout en gardant tous les bons, et peut potentiellement
		  	 accélérer le traitement de HG-CoLoR 
\end{itemize}

\section{Jour 233}

\begin{itemize}
	\item Récupération résultats Yeast PB et test d'assemblage => Pas beaucoup mieux qu'avec MinION pour l'assemblage
\end{itemize}

\section{Jour 234}

\begin{itemize}
	\item Test d'exctration des 32-mers après assemblage des 16-mers (sans paramètre sur leur nombre) => On
		  en obtient peu, mais ils sont d'assez bonne qualité (99.70 \%)
		  => Besoin d'assembler from scratch avec le graphe hybride pour obtenir l'intégralité des 32-mers
		  
	\item Réextraction de tous les 16-mers des SR (avec un trou au milieu de taille 0-10), avec et sans limite
		  de fréquence à 5
		  
	\item Réextraction de tous les 16-mers des LR (avec un trou au milieu de taille 0-10), sans limite
		  de fréquence		  
		  
	\item Adaptation du code de HG-CoLoR pour permettre la génération de tous les (2*k)-mers + test avec les 16-mers des SR
			=> Après test, sort des résultats convenables, mais pas assez de k-mers (ne couvre pas tout le gen ref)
			=> Besoin de revoir la màj de la liste des k-mers déjà visités ?
			=> En changeant la méthode de maj, et en prenant des k-mers des SR sans limite de fréquence : Trop de k-mers,
			   et faible identité
			   => Besoin de trouver un seuil ?
			   => Test avec au moins fréquence de 3 : Mauvais résultats (trop peu de 32-mers)
			   => Test avec une fréquence de 1, mais avec minOverlap à 14 : Trop de k-mers
			   => Test avec une fréquence de 1, mais avec minOverlap à 15 : Trop de k-mers
			   => Test avec au moins fréquence de 2, minOverlap à 15 : Trop peu de k-mers
			   => Test avec au moins fréquence de 2, minOverlap à 14 : Trop peu de k-mers
			   => En fait, minOverlap ne change rien car si on trouve un overlap de longueur n, on ne cherche plus
			   	  avec n - 1.
\end{itemize}

\section{Jour 235}

\begin{itemize}
	\item Réextraction de tous les 16-mers avec un trou d'emplacement variable et de taille fixe, en fixant le nombre min à 5
		  + utilisation du graphe hybride pour générer des 32-mers => Génère BEAUCOUP TROP de 32-mers, de très mauvaise qualité
		  => Test en passant à 10 pour le nombre min : Toujours trop de k-mers, de mauvaise qualité
		  
	\item Intersection / union de tous les 16-mers avec trou au milieu générés au jour 233 => Ne donne rien de plus qu'avant
		  => Pas mal de trucs en commun quand on regarde les k-mers espacés des deux côtés
		  => Impossible de chercher dans l'index des LR => À cause de certains des SR => Purge pour pouvoir lancer les tests
\end{itemize}

\section{Jour 236}

\begin{itemize}
	\item Purge des k-mers de SR causant les seg fault à la main => bcp trop long, mais même pattern ?

	\item Test extraction des 8-mers fréquents des LR, et de construction des 16-mers
		  => Impossible d'indexer des 8-mers avec PgSA
		  
	\item Test reconstruction de l'index des LR à partir du fasta produit par GkAmpi,
		  puis recherche des 16-mers de SR => Ne marche pas non plus, mais pattern de seg fault différent
		  
	\item Test de purge des k-mers de SR causant les seg fault directement à partir des patterns erronés
		  => Marche nickel !
		  
	\item Fin des calculs intersections / unions de tous les 16-mers
		  => On retrouve peu de SR espacés dans les LR : bizarre ?
	
	\item Test de HALC
		  => Sur ADP1 : Corrige plus de LR, ne prend que 4h, mais pire qualité que nous (96.61 au mieux)
		  => Sur Coli : Corrige autant de LR, ne prend que 26min ???, mais légèrement pire qualité que nous (99.50 au mieux)
		  => Sur Yeast : Corrige plus de LR, ne prend que 3h, mais pire qualité que nous (98.45)
		  => A voir sur l'assemblage
	
	\item Test reconstruction des 32-mers du gen ref à partir des 16-mers du genref
		  => Produit un peu trop de 32-mers, mais de bonne qualité (99,82)
		  => Test de correction de ces 32-mers avec Quorum : n'augmente quasi rien
\end{itemize}

\section{Jour 237}

\begin{itemize}
	\item HALC produit des reads soit très courts (pour le split, bonne qualité) soit longs (corrected et trim, mauvaise qualité)
		  => Il est donc clairement mauvais, même si rapide
		  
	\item Test extraction des 16-mers contigus en montant peu à peu le seuil, pour voir à partir de quand
		  les 16-mers extraits deviennent fiables
		  => 20 : 50/50
		  => 30 : 50/50
		  => 40 : 50/50
		  => 50 : 50/50
		  => 60 : + de unfound
		  => 70 : presque que des unfound
		  => 80 : presque que des unfound
		  => Pareil jusque 100
		  
	\item Test extraction des 8-mers contigus => Même avec seuil de fréquence à 1000, on ne récupère pas
		  tous les 8-mers du gen ref, et on a encore des mauvais 8-mers
		  
	\item Réunion w/ GT
	
	\item Poursuite diapos, 75\% faits
	
	\item Lancement correction NaS sur Ecoli afin d'essayer de récupéter le temps d'exec
\end{itemize}

\section{Jour 240}

\begin{itemize}
	\item Extraction des 16-mers espacés (étendus) des LR et recherche dans les SR (pour catch les suppressions)
		  => Pour les 16-mers, besoin d'extraire des (16-gap)-mers, donc difficile de mettre le gap au milieu
		  => Résultats très différents si on met le gap plus à droite ou plus à gauche
		  
	\item Test génération 16-mers étendus des LR avec un trou d'emplacement variable, freq = 5
		  => Semble permettre de catch pas mal de 16-mers des SR
		  => L'union avec les 16-mers espacés des LR (trou 0-10 au milieu) présents dans les SR semble prometteuse
\end{itemize}

\section{Jour 241}

\begin{itemize}
	\item Surveillance exam
	
	\item Génération 16-mers espacés des LR avec un trou d'emplacement variable et de taille 2 ET pareil avec taille 1
		  => Recréation des fichiers
		  
	\item Union 16-mers espacés taille 1 et 2 + 16-mers étendus taille 1 => Pas grand chose en plus dans les SR
		  par rapport à la version sans 16-mers espacés taille 2
	
	\item Génération 16-mers étendus des LR avec un trou d'emplacement variable et de taille 2
	
	\item Union et recherche des deux ensembles précédents dans les SR (espacés + étendus, 1 et 2 trous)
		  => on identifie tout, à 100k près
\end{itemize}

\section{Jour 242}

\begin{itemize}
	\item Réunion w/ TL \& AL
	
	\item Génération des 32-mers à partir des bons 16-mers extraits des LR
		  => Très mauvais avec les bons 16-mers seuls
		  => Pas mal avec les RC en plus, un peu trop de 32-mers mais bonne qualité globale (99.64 \%)
		  
	\item Étude du GC-content des k-mers espacés / étendus des LR avec un trou
		  => Majoritairement : Même proportions, puis AT, puis GC, pas très intéressant ?
		  
	\item Recherche seuil de k à partir duquel les k-mers sont uniques dans ADP1
		  => Pas d'énorme différence entre 16 et 64, 20 semble pas mal, bon compromis (+ 0.2 \% par rapport à 16, à 0.1 \% de 64)
		  
	\item Calcul des 20-mers espacés / étendus des LR (vieille chimie)
	
	\item Récupération de données Yeast / ADP1 de R9.4
		  => Comparaison ADP1 old / R9.4 par qualité (36.1 \% VS 42 \%) et recherche des 16-mers (65,6 \% VS 24 \%)
		  => Comparaison Yeast old / R9.4 par qualité : 8.2 \% vs 67.9 \%
		  => Nouvelle chimie un peu mieux, mais probablement difficile également de faire quelque chose avec les k-mers (ADP1)
		  => Nouvelle chimie BEAUCOUP mieux (Yeast)
		  => Lancement HG-CoLoR sur Yeast
\end{itemize}

\section{Jour 243}

\begin{itemize}
	\item Recherche sur bug HG-CoLoR de FX
		  => BLASR ? Non, quelques LR avec un seul seed, mais pas la plupart
		  => Bug dans le code ? Non, marche sur ADP1
		  => Qualité des SR ? Non, ceux de FX sont mieux
		  => Qualité des 64-mers ? Non, ceux de FX sont mieux aussi (99.35 vs 99.98)
		  => Nombre des 64-mers ?
		  			=> Dans les SR corrigés : Beaucoup trop (+ de x2) dans le jeu de FX
		  			=> Dans les SR bruts : Beaucoup trop (+ de x3) dans le jeu de FX
		  => Trop de backtracks ? Non, la plupart des sources n'overlappent que peu / pas de k-mers
		  => Test avec les anciens SR : Marche bien
	
	\item Fin calcul 20-mers espacés (2 gaps) + recherche des 20-mers espacés ADP1 (vieille chimie) dans les SR
		  => Mauvais avec 2 trous
		  => Recalcul car les calculs n'étaient pas faits en canonique avec GkAmpi
		  
	\item Tout ce qui a été fait sur les 16-mers est à refaire (car GkAmpi pas réglé en canonique)
		  => Lancement d'un script pour faire ça pendant la nuit (LR / SR avec trou au milieu, LR avec trou qui se déplace len 1-2)	
		  
	\item Comparaison 16-mers contigus vieille chimie / R9.4 => R9.4 a l'air pire (en nombre de 16-mers dans les SR)
	
	\item Calcul des 16-mers étendus ADP1 R9.4
\end{itemize}

\section{Jour 244-246}

\begin{itemize}
	\item Recalcul des union / inter avec les ensembles de 16-mers espacés / étendus des LR (trou emplacement variable)
		  (en calculant les 16-mers espacés canoniques avec GkAmpi)
		  => 1 et 2 trous : Un peu mieux, mais pas beaucoup de changement 
		  
	\item Fin recalcul 16-mers uniquement espacés (SR / LR, trou au milieu) + reprise des résultats
		  (en calculant les 16-mers espacés canoniques avec GkAmpi)
		  => Très peu de différence par rapport à la version non canonique, bien qu'un peu mieux
		  
	\item Fin recalcul des 20-mers espacés (2 gaps, GkAmpi)
		  => Bien mieux que les résultats d'avant (manque 400k 20-mers)
	
	\item Calcul des 16-mers espacés / étendus ADP1 R9.4
		  => Après union avec les 16-mers étendus : Pire que la vieille chimie
	
	\item Recherche dans code source jellyfish => Impossible de modifier pour espacer les k-mers ici
	
	\item Solution retenue : sortir tous les k-mers espacés / étendus direct sur la sortie standard, sans les compter
		  (donc, avec doublons), et rediriger vers l'entrée de Jellyfish pour indexer.
		  Commande : \textsc{getSpacedKMers | jellyfish count -m 16 -s 500M -t 8 -C /dev/stdin}
		  Une fois les index construits pour plusieurs seeds différents, merge les index et extraitre
		  les k-mers
		  
	\item Extraction de tous les 16-mers espacés avec un trou taille 1 emplacement variable dans une même base Jellyfish
		  => Même en mettant un gros -L, impossible d'extraire des bons 16-mers 
\end{itemize}

\section{Jour 247}

\begin{itemize}
	\item Récupération runtime NaS SENSITIVE sur Ecoli + lancement NaS FAST sur ADP1
	
	\item Exatraction des 16-mers étedus avec un trou de taille 1 emplacement variable dans une même base Jellyfish
		  => Impossible ? Beaucoup trop de 15-mers quand on ne limite pas avec un -L
		  => En prenant les 15-mers apparaissant un certain nombre de fois ? => Non, car en sortant les fréquents
		  	 dans un fasta, on ne peut pas récupérer leur nombre d'occurrences
		  => En fait, même problème en sortant les non fréquents : Besoin de lancer extend sur les reads direct
	
	\item Test recherche d'un set de 16-mers étendus dans l'index des SR
		  => freq = 10 : Pas terrible 
		  => freq = 20 : Pas mieux
		  => Pas grand chose à déduire des fréquences pour le moment, à voir avec tous les 16-mers étendus,
		  	 et en combinant avec les 16-mers espacés
		  
	\item Calcul de tous les sets de 16-mers étendus avec un trou (13h de runtime)
			
	\item Exctraction de tous les 16-mers espacés avec un trou taille 2 emplacement variable dans une même base Jellyfish
		  => En combinant 1 + 2 trous : Même avec une très haute fréquence, on a toujours bcp de mauvais k-mers,
		  	 voire même plus que de bons (pour -L 150)
		  	 
	\item Test assemblage (sans correction) des raw LR ADP1 avec Canu
		  => Impossible, même après filtrage des LR courts
	
	\item Extraction des LR se mappant à + de 90\% de ADP1 + extraction des k-mers étendus / espacés
		  => Bof, car les LR ne couvrent pas 100\% du génome, il y en a trop peu
\end{itemize}

\section{Jour 248}

\begin{itemize}
	\item Génération des 2 ensembles : 16-mers espacés / étendus 1 trou et 16-mers espacés / étendus 1 trou et 2 trou
		  => Fichier de 16-mers étendus supprimé comme un GROS CONNARD :) RECALCUL
		  => Pour avoir les fréquences de tous les 16-mers contigus / espacés / étendus possibles
		  
	\item Extraction des MAW des SR, pour pouvoir filter out les LR / k-mers contenant ces mots
		  => Le programme donne les MAW pour chacune des séquences séparemment, et non pour
		  l'ensemble des séquences
		  => => Extraction des MAW du GR directement, pour tester
		  => Possible de récupérer l'ensemble des MAW de tous les SR avec sort | awk, comme pour les LR
		  => Besoin maintenant de trouver comment repérer ces MAW dans les LR, car impossible d'indexer avec PgSA (pas tous de même taille)
		  
	\item En fait, si on extrait les 16-mers contigus des LR, et qu'on cherche dans les bons 16-mers
		  des SR, on trouve presque tout ce dont on a besoin (car maintenant on cherche dans les bons
		  k-mers des SR, alors qu'avnat on cherchait aussi parmi les mauvais, donc on identifiait
		  une faible proportion de 16-mers, mais on avait déjà les bons)
		  
	\item Extraction des LR se mappant à + de 70\% de ADP1 + extraction de leurs 16-mers contigus 
		  => On perd très peu d'info par rapport à l'extraction des 16-mers contigus de tous les LR,
		  	 mais on diminue énormément (x13) le nombre de 16-mers total (sans threshold sur la fréquence)
		  	 => Avec threshold sur la fréquence : Pas possible au dessus de 2, réduit encore bcp le nombre
		  	 de mauvais 16-mers, et relativement peu le nombre de bons
		  => Intéressant de se débarrasser de ces mauvais LR, pour extraire ensuite les bons k-mers, sûrement + facile
		  => Semble en fait revenir à peu près au même que de prendre directement les 16-mers fréquents (-L 5) de tous les LR,
		  	 peut être même un peu moins bien
		  => Abandon
		  
	\item Idée : Extraire les MAW de tous les LR, et regarder les plus récurrents, puis virer les LR / k-mers
		  contenant ces MAW ?
		  - Récupération des MAW read par read (avec et sans reverse) => => Étude suivant sans les reverse
		  - Comptage / compaction et formatage FASTA des résultats => 12M de MAW
		  - Recherche des MAW dans les SR (donne pareil dans le gen ref) en fonction de leur fréquence
		  	=> Basse fréqence (1) : Beaucoup n'apparaissent pas dans les SR (4/5ème)
		  	=> Haute fréquence (10k) : Apparaissent tous
		  	=> Haute fréquence (Au moins 5k) : Apparaissent tous
		  	=> Moyenne fréquence (1k-5k) : Apparaissent presque tous (à 65 / 100k près)
		  	=> Moyenne-haute fréquence (1k-10k) : Aparaissent presque tous, 127 942 matches pour 65 non match
		  		=> Car les choses apparaissant trop souvent sont très courtes
		  		=> + intéressant de se pencher sur les choses rares, + longues
		  	=> Récupération des 16+ puis des 16-mers des MAW basse fréquence (1) : Presque aucun n'est présent (sur 4xx k)
		  	=> Basse fréquence (1-1k) : La moitié dans les SR / l'autre non
		  	=> Moyenne fréquence (10-1k) : Presque tout dans les SR (1.6M vs 160k)
		  	=> Basse fréquence (1-10) : + d'unfound que de found (2/3 unfound)
		  	=> Basse fréquence (1-5) : + d'unfound que de found (2/3 unfound)
		  		=> + minLen 12 + 12 mers => Pas une grande différence entre found et unfound
		  		=> + minLen 13 + 13 mers => bcp d'unfound, mais nombre non négligeable de found
		  		=> + minLen 14 + 14 mers => Pareil
		  		=> Inutile d'aller au dessus
		  		
	\item Récupération des MAW, de longueur max 16 => seulement 500k en moins par rapport à tous les MAW
		  => Récupération des MAW de longueur = 16 => Seulement 250k, aucun présent dans les SR
		  => Les MAW récupérés n'ont donc aucune garantie d'être dans les SR (logique en fait)
		  	
	\item Correctifs mineurs sur diapos
\end{itemize}

\section{Jour 249}

\begin{itemize}
	\item Génération ensemble 16-mers espacés étendus 1 trous + ensemble 16-mers étendus un trou et 16-mers espacés 1--2 trou
		  => Besoin de recalculer les 16-mers espacés pour avoir la même tailel de hash (1 et 2 trous)
		  => Recalcul + génération
		  => Refail encore lors de la fusion des fichiers de 16-mers espacés (oublié le -o ...) => => RERERERERERERERECALCUL
		  
	\item Idée : Déterminer les bons k-mers selon la présence de MAW dedans ? (indexer les k mers, fichier requête avec
		  les MAW, sortir les k-mers contenant un MAW), car tous les MAW de grande fréquence sont dans les SR
		  => Test de récupération de bons 16-mers à partir d'un MAW exemple : Beaucoup sont unfound après recherche dans les SR...
		  => Besoin de virer les MAW inclus dans d'autres (ie si AA, AAA et AAAA, ne garder que AAAA)
			 => Script python créé
		  => Si on n'exige qu'un MAW par 16-mer : On ne filtre rien
		  => En créant un PgSA par 16-mer LR : seg fault
		  => En faisant les requêtes avec GkAmpi ? Permet de récupérer l'id du read (ici, du k-mer) dans lequel apparait une séquence (ici un MAW)
		  	 => À voir
		  => Recherche de MAWs dans un bon k-mer : 8 apparitions ; dans un mauvais k-mer : 1-6 apparitions (en prenant ici des k-mers des SR)
		  => Recherche de MAWs dans un mauvais k-mer : 9 apparitions (en prenant ici un k-mer des LR)
		  => Programmation d'un (mauvais) script pour tester les apparitions dans tous les mauvais k-mers => Pas concluant avec 1k-10k
		  => Test avec 5k-10k : Pas concluant non plus
		  => Retest avec 1k-10k + filtration des MAW de len < 10 : Semble permettre de filtrer certains mauvais k-mers
			 => Le fait qu'exiger un MAW par 16-mer ne filtrait rien venait de l'absence de filtre des courts MAWS
\end{itemize}

\section{Jour 250}

\begin{itemize}
	\item Fusion des bases .jf de 16-mers enfin obtenues, avec un trou de taille fixe se déplaçant
	
	\item Étude des fréquences de ces 16-mers en tri en 3 paquet (sous / sur / autre représenté) + recherche
		  dans les SR
		  => + de 1000 (sur-représenté) : mauvais
		  => 100 à 1000 (autres) : mauvais
		  => - de 100 (sous représenté) : mauvais 
		  => 50 à 100 : mauvais
		  => Autres tests : mauvais
		  
	\item Programmation recherche de MAW dans les k-mers aec PgSA (on sort un k-mer s'il a un MAW)

	\item En cherchant aussi les RC des MAW dans les k-mers, on couvre en fait mieux un + grand nombre de k-mers
		  => Il y en a tout de même 220k sans aucun MAW dedans (dans les k-mers des LR non présents dans les SR)
		  => Mais parmis les bons k-mers, on en a quand même 620k sans aucun MAW
		  => Tous les MAW sont dans les SR, mais tous les k-mers des SR n'ont pas de MAW
		  	 => Quand on extrait les k-mers des SR avec au moins un MAW dedans, on en obtient que 2.5M
		  => Retest en prenant les MAW avec le switch -r 
		  	 => Toujours presque tous présents dans les SR
		  	 => Parmi les k-mers des LR non présents dans les SR : 3k sans aucun MAW dedans
		  	 => Parmi les bons k-mers, 11k sans aucun MAW
		  	 => Quand on extrait les SR avec au moins un MAW dedans : 3.51M sur 3.52M
		  => Semble difficile de déterminer les bons k-mers à l'aide de MAW
		  
	\item Génération de 16-mers étendus avec 2 trous : Impossible, bcp trop long
	
	\item Installation de DE-Kupl => Impossible d'installer ses dépendances de merde
\end{itemize}

\section{Jour 251-253}

\begin{itemize}
	\item Lancement de HG-CoLoR param par défaut / full DBG sur ADP1
		  => Qualité un peu moins bonne avec DBG (0.1 \%)
		  => Assemblage très légèrement moins bon avec DBG (moins de bases du gen ref couvertes)
		  
	\item Lancement de HG-CoLoR param par défaut / full DBG sur Ecoli
		  =>	 Qualité moins bonne avec DBG (0.06 \%)
		  => Assemblage légèrement moins bon avec DBG
		  => Plus long avec DBG
		  
	\item Adaptation du code PgSA pour déterminer la couverture en MAW de chaque k-mer (nb de MAW présent / k-mer)
		  => Les bons et les mauvais ont à peu près la même couverture en MAW
		  => Les MAW ne nous serviront pas à déterminer les bons 16-mers
		  => Voir le nb de bases couvertes plutôt que le nombre ?
		  
	\item Adaptation code PgSA pour déterminer le coverage en MAW de chaque base de chaque k-mer
		  => On a effectivement certaines bases non couvertes par les MAW (dans les bons comme dans les mauvais k-mers)
		  => Découverte d'une erreur dans le code de filtrage de HG-CoLoR + correction
		  => En fait, mauvais résultats si on converse les MAW trop longs (pas assez de bases des k-mers couvertes)
		  => Retour aux MAW courts => Ne semble pas beaucoup mieux
		  => Retour aux MAW sans élimination des MAW inclus dans d'autres => Toujours pas top, présence de MAW bcp trop courts
		  => Filtrage de la taille à 8 (sans virer les MAW inclus) => Ne change rien
		  => Moyenne sur le nombre de base couvertes pour avoir un coverage en X => Aucune info
		  
		  
	\item Nouveaux tests sur les fréquences d'apparition des 16-mers
		  => Difficile d'en tirer qqch
	
	\item Récupération runtime NaS FAST sur ADP1 + lancement NaS SENSITIVE sur ADP1
	
	\item Retouches correctifs article HG-CoLoR (synthetic, simulated, + conclusions avec HG > DBG)
	
	\item N'extraire que les k-mers fréquents des SR corrigés pour HG-CoLoR ?
		  => Non, car les SR utilisés comme seeds peuvent contenir des mauvais k-mers
		  
	\item HG-CoLoR ne donne plus du tout les bons résultats... Bien moins bon assemblage...
		  => Besoin de voir comment corriger le problème de tri version c++ ?
		  => Lancement sur Coli avec l'ancienne version, voir si on obtient les mêmes résultats qu'avant
		  		=> On obtient bien les mêmes résultats qu'avant
\end{itemize}

\section{Jour 254}

\begin{itemize}
	\item Fin retouches papier HG-CoLoR (synthetic / simulated / etc)
	
	\item HG-CoLoR redonne bien les mêmes résultats si on lance l'ancienne version avec un fichier de mapping différent,
		  le bug vient donc de la fonction de tri ?
		  => Lancement de nouvelle / ancienne version sur M12D et recherche pour obtenir les mêmes résultats
		  => Les fichiers d'alignement ne sont pas les mêmes
		  	=> Car script pas mis à jour dans l'ancienne version, retest après màj
		  	=> Les fichiers alignements ne sont toujours pas les mêmes, mais sur la V1, même en relançant plusieurs fois, on a toujours les mêmes alignements
		  	=> Retest sans traiter les fichiers
		  	=> Toujours différent, mais les LR n'étaient pas formatés pareil, retest 
		  	=> Même fichiers d'alignements
		 => Mais les SLR obtenus ne sont toujours pas les mêmes, à cause de la fonction de tri ?
		 => Recherche d'un LR différent et étude du fichier de partAln
		 	=> Le fichier aln est le même, mais pas dans le même ordre
		 	=> Le problème vient donc bien du sort
		 	=> Difficile à régler ?
		 => Impossible d'obtenir le même sort qu'en C, avant, il semble assez aléatoire et dépendant du pivot pour le qsort
		  
	\item Test modification HG-CoLoR sort 
		  => sur la fonction <, en considérant que < et = renvoient le même res
		  	=> Seg fault
		  => Sur la fonction <, en prenant en compte la longueur de l'alignement en cas d'égalité de pos alignement
		  	=> Plus de seg fault, mais toujours pas le même res
		  => En comparrant ensuite le score en cas d'encore égalité
			=> Toujours pas les mêmes res 2 fois de suite
		  => En comparant ensuite les séquences en elles mêmes
		  => On récupère bien maintenant les mêmes résultats si on lance deux fois de suite (aussi bien alignement que LR corrigés)
		  => Lancement sur full Coli
	
	\item Idée : Génrer des k-mers plus grands à partir des bons MAW de taille 9
		  => PgSA ne peut indexer des reads de cette taille		  
		  
	\item Bug sortie HG-CoLoR, on peut avoir plusieurs tags qui se suivent, et plusieurs séquences qui se suivent ??
		  => correction en sortant tag ET LR sur la même ligne de code
		  
	\item Run Jabba avec k = 64 et k = 59 => Impossible avec 64, donc test avec 65 : marche
		  => Voir demain si on fait 64 / 65 / 59
		  => Semble pire avec une taille de k-mer plus petite
\end{itemize}

\section{Jour 255}

\begin{itemize}
	\item Dernières retouches HG-CoLoR

	\item Réunion w/ TL \& AL => Validations modifs
	
	\item Récupération correction HG-CoLoR Coli avec nouvel version du tri + assemblage 
		  => Encore des bugs de merde de mauvais format => Correction du format du fichier + de l'erreur dans le code
		  => Assemblage : Toujours un peu moins bon, mais pas énormément, autres métriques très similaires
		  => Recherche de nouveaux paramètres pour diminuer le nb de contigs => Pas trouvé
		  => Comparaison avec version DBG une dernière fois => 
		  
	\item Recalcul des MAW sur fichier LR + RC-LR, en virant les MAW inclus + comparaison des MAW fréquents
		  => En Forward : Plus que F sur LR seuls, mais moins que F+R sur LR seuls, même remarque sur la longueur moyenne des
		  => En F+R : Bien plus que F+R sur LR seuls, et longueur bien meilleure
		  => Besoin de voir si on peut récupérer des choses longues et bonnes
		  
	\item Recherche de correspondances k-mers / MAW
		  => Les 64-mers (même mauvais) des LR semblent en fait contenir 100\% de bons 9-mers se chevauchant sur len = 8
	
	\item Problème avec le switch -C de Jellyfish
		  => Quand on compte les 8-mers + les RC de ces 8-mers avec Jellyfish, utiliser le switch C ne donne pas le bon nombre de k-mers
		  	 (on peut avoir un k-mer ET son RC qui apparaissent dans le fichier de dump)
		  	 
	\item HG-CoLoR peut séparer 2 fragments d'un même LR corrigé par plusieurs LR corrigés dans le fichier de sortie
		  => Besoin de repasser par le système de fichiers intermédiaires pour rectifier le tir
		  
	\item Étude des 8-mers et 9-mers des SR / GR, afin de voir si les MAW sont vraiment intéressants
		  SR (sans freq) => 32 896 8-mers
		     			=> 131 064 9-mers
		     			=> 521 533 10-mers

		  SR (-L 5) => 32 896 8-mers 
		  		   => 130 830 9-mers
		  		   => 491 587 10-mers
				   => 1 882 748 11-mers

		  GR => 32 858 x2 = 100\% 8-mers possibles
		     => 129 317 x2 = 98.7\% 9-mers possibles
		     => 470 422 x 2 = 89.73\% 10-mers possibles
		     => 1 284 353 x2 = 61.24\% 11-mers possibles
		     => 2 785 593 x 2 = 33.2\% 12-mers possibles
		     
		 => k-mers bons SR = 2 x k-mers GR
		  
	\item Besoin de trouver des MAWs plus longs pour pouvoir en faire qqch
		  => Jusque 10, presque tout est dans le gen ref
		  => Aller jusque 12 apporterait de l'info
		  => Mais il y a presque autant de 12 que de 16 mers dans le GR / SR, donc difficile
		  => Explorer la piste des MAW non présents dans le GR / SR ?
		  
	\item Étude des MAW peu fréquents (donc non présents), < 100 occ : Meilleure longueur, très peu de bons, bcp de mauvais
		  => besoin d'identifier tous les mauvais
\end{itemize}

\section{Jour 256-260}

\begin{itemize}
	\item Étude des MAW fréquents récupérés avec -r 1 dans LR + RC-LR
		  => Plus longs que ceux récupérés sur LR seuls
		  => On ne peut récupérer que 5k 12-mers
		  => De plus, ils n'aparaissent pas tous dans le gen ref
		  => Inutile de se pencher sur les MAW fréquents
		  
	\item Étude des MAW peu fréquents
		  => Toutes les bonnes choses sont toujours presque identifiées au milieu de nombreuses mauvaises choses
		  => qu'en faire ?
		  
	\item Étude : 2 LR se mappant au même endroit ont-ils les mêmes MAW ?
		  => Beaucoup de MAWs communs, qq MAWs différents (sans RC les LR traités)
		  En modifiant un peu un des LR => Des MAWs apparaissant très fréquemment
		  
	\item Étude : Peut-on récupérer des LR bruts similaires avec Commet ?
		  => Test avec un LR : k = 32 => Aucun LR similaire
		                     : k = 16 => 41 625 LR similaires
		                     : k = 24 => Aucun LR similaire
		                     : k = 20 => 25 LRs similaires
		  => Vérification sur les LRs corrigés : On en récupère 11 ayant pu être corrigés, 8 se mappent effectivement à peu près sur la même zone
		  => Peut-être prometteur ?
		  => Test avec 3 20-mers en commun : On récupère moins de LR similaires (10), très peu de corrigés (3), et encore moins se mappant
		  	 dans la même région (2)
		  => Test avec 2 22-mers en commun : On ne récupère que 4 LR similaires
		  => Semble bien de rester sur 2 20-mers communs 
		  => En fait non ? En sélectionnant un autre LR comme LR de base, on obtient beaucoup (120) de LRs similaires
		  	 => Peut être bien pour un gros consensus ?
		  
	\item Script permettant d'extraire LR par LR, les LR similaires
		  => Bête, car tous les LR d'un ensemble ne partagent pas forcément tous 2 k-mers entre eux
		  => Il sera donc impossible de récupérer un set de reads par région du gen ref
		  => Sûrement possible de corriger LR par LR en récupérant les LR similaires à chaque fois, mais comment ?
		  => Possible quand même de récupérer un set de LRs similaires pour chaque LR
		  
	\item Récupération du coverage en X pour HG-CoLoR, NaS, CoLoRMAP, Jabba, + ajout de la case dans tableau
	
	\item Test correction de k-mers des LR avec Karect (car capable de gérer les indels)
		  => Impossible de lancer la correction, seg fault
		  => Test avec les 64-mers plus fréquents : Déjà avec -L 2, trop peu de k-mers
		  => Test avec les 32-mers
		  
	\item Correction de l'exemple OLG / DBG / HG sur les diapos de présentation
		  + avance sur la préparation des diapos seeds linking
		  
	\item Run de HG-CoLoR sur Yeast beaucoup trop long sur machine perso (< 100 LR à l'heure)
		  => Test sur ADP1 : Bien rapide comme d'habitude
		  => À cause du trop gros fichier d'alignement ?
		  => Rerun avec 16 threads : Toujours trop lent, 1000 LRs en 5 heures
		  => Test sur machine Crihan : Bien + de 1k de LR corrigés / heure, on laisse
		  
	\item Tests sur les nombres moyens de LR similaire à un LR donné avec Commet
		  => Très long de tout obtenir, mieux de voir ce qu'on peut faire LR par LR,
		  	 avant de lancer l'extraction
\end{itemize}

\section{Jour 261}

\begin{itemize}
	\item Fin préparation diapos
	
	\item Étude des MAWs non fréquents : Ok, pas mal avec 1 apparition et len 20
		  => Test discrimination des 32-mers (récupérer les mauvais) : Ne donne toujours rien, très peu de 32-mers contiennent un MAW
		  	 => De plus, les 32-mers contenant un MAW (pourtant erroné) sont présents dans les SR
		  => Test discrimination avec d'autres valeurs : Pas concluant
		  
	\item Test sur la couverture des 32-mers avec les MAWs non fréquents => Problème : Impossible de récupérer la couverture correctement
		  	=> Non, on récupère bien la couverture moyenne et non le nombre de MAWs qui se mappent
		  => bons et mauvais 32-mers ont la même couverture
		  
	\item Test sur le nombre de MAWs présent par 32-mers => Bon et mauvais 32-mers ont autant des MAWs
\end{itemize}

\section{Jour 262}

\begin{itemize}
	\item Étude k-mers / MAWs d'un jeu de LR similaires
	
	\item Idée : Récupérer les plus long sous-mots communs à deux LR similaires
		  => Pas concluant
		  => Extraire les k-mers de ces sous-mots n'est pas concluant non plus
		  
	\item HG-CoLoR va en fait être plus rapide que prévu sur Yeast
		  
	\item Extraction de bons k-mers en cherchant les similaires aux uns et autres autres,
		  puis en cherchant les plus longs sous-mots communs ? Car ils permettent de capturer les indels
		  => Sur un sous ensemble de 64-mers similaire à un 64-mer donné : Les sous-mots apparaissant souvent ne s'alignent pas,
		  	 mais présence de beaucoup d'alignement à 100\% ou avec une seule indel
		  => Sur tous les 64-mers apparaissant au moins 2 fois : De même, les sous-mots apparaissant souvent de s'alignent pas,
		  	 mais présence de beaucoup d'alignement à 100\% ou avec une seule indel
\end{itemize}

\section{Jour 263}

\begin{itemize}
	\item Étude des résultats nouvelle version HG-CoLoR sur Yeast (Début : 28, 11h43 - Fin : 31, 2h41 => 63 heures)
		  => Pareil sur les métriques / l'alignement
		  => Sur l'assemblage : Semble un peu moins bon
		  => Recherche de bons paramètres pour assemblage
	
	\item Lancement HG-CoLoR sur ADP1 et Ecoli
\end{itemize}


\end{document}
